{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SJ Training fNIRS Data Analysis</h1>\n",
    "Written by Ansley Kunnath\n",
    "Updated July 29, 2024\n",
    "Python v3.9.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "from scipy.stats import ttest_rel, zscore\n",
    "import os.path as op\n",
    "import statsmodels.formula.api as smf\n",
    "import mne_nirs.preprocessing\n",
    "import mne_nirs.statistics\n",
    "import mne_nirs.utils\n",
    "import mne\n",
    "from mne.preprocessing.nirs import tddr\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix  \n",
    "from mne_nirs.channels import get_long_channels\n",
    "\n",
    "# Open plots in new window\n",
    "%matplotlib qt \n",
    "\n",
    "print(\"All done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate files\n",
    "\n",
    "subjects = ('201 202 203 204 205 206 207 208 209 212 213 214 215 216 217 218 219 221 223 224 225 226 228 229 230 231 232 233 234').split() #\n",
    "\n",
    "# Mapping of subjects to groups\n",
    "subject_to_group = {\n",
    "    201: \"trained\",\n",
    "    202: \"control\",\n",
    "    203: \"trained\",\n",
    "    204: \"control\",\n",
    "    205: \"control\",\n",
    "    206: \"control\",\n",
    "    207: \"trained\",\n",
    "    208: \"control\",\n",
    "    209: \"control\",\n",
    "    212: \"trained\",\n",
    "    213: \"trained\",\n",
    "    214: \"trained\",\n",
    "    215: \"control\",\n",
    "    216: \"trained\",\n",
    "    217: \"control\",\n",
    "    218: \"control\",\n",
    "    219: \"trained\",\n",
    "#    220: \"control\", #sampling rate = 2.40 Hz instead of 4.8\n",
    "    221: \"trained\",\n",
    "    223: \"trained\",\n",
    "    224: \"control\",\n",
    "    225: \"trained\",\n",
    "    226: \"control\",\n",
    "    228: \"trained\",\n",
    "    229: \"control\",\n",
    "    230: \"trained\",\n",
    "    231: \"trained\",\n",
    "    232: \"control\",\n",
    "    233: \"trained\",\n",
    "    234: \"control\",\n",
    "}\n",
    "\n",
    "sfreq = 4.807692\n",
    "conditions = ('A', 'V', 'AV', 'W')\n",
    "groups = ('trained','control')\n",
    "days = ('1', '3')\n",
    "runs = (1, 2)\n",
    "\n",
    "condition_colors = dict(  # https://personal.sron.nl/~pault/data/colourschemes.pdf\n",
    "    A='#4477AA',  # sblue\n",
    "    AV='#CCBB44',  # yellow\n",
    "    V='#EE7733',  # orange\n",
    "    W='#AA3377',  # purple\n",
    ")\n",
    "exp_name = 'av'\n",
    "duration = 1.8\n",
    "design = 'event'\n",
    "plot_subject = '205'\n",
    "plot_day = 1\n",
    "plot_run = 1\n",
    "beh_title, beh_idx = 'AV', 0\n",
    "filt_kwargs = dict(\n",
    "    l_freq=0.01,\n",
    "    h_freq=0.2) \n",
    "run_h = True  # regenerate HbO/HbR\n",
    "n_jobs = 4  # for GLM\n",
    "\n",
    "# SET FOLDER LOCATIONS\n",
    "# I save the output files outside of the folder that's uploaded to Github\n",
    "current_directory = %pwd\n",
    "os.chdir(current_directory)\n",
    "\n",
    "raw_path = '../../data'\n",
    "proc_path = '../../processed'\n",
    "results_path = '../../results'\n",
    "subjects_dir = '../../subjects'\n",
    "os.makedirs(proc_path, exist_ok=True)\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(subjects_dir, exist_ok=True)\n",
    "#mne.datasets.fetch_fsaverage(subjects_dir=subjects_dir, verbose=True)\n",
    "\n",
    "use = None\n",
    "all_sci = list()\n",
    "plt.rcParams['axes.titlesize'] = 8\n",
    "plt.rcParams['axes.labelsize'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "got_bad = 0\n",
    "got_total = 0\n",
    "\n",
    "# Prep making bad channels report\n",
    "bad_channels_filename = op.join(results_path, 'bad_channels_report.csv')\n",
    "with open(bad_channels_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Subject', 'Day', 'Run','Percent Bad'])\n",
    "\n",
    "def normalize_channel_names(channels_set):\n",
    "    return {name.split()[0] for name in channels_set}\n",
    "\n",
    "def add_bad_channel_entry(subject, day, run, percentage_bad):\n",
    "    with open(bad_channels_filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([subject, day, run, f'{percentage_bad:.2f}%'])\n",
    "\n",
    "def piecewise_linear_detrend(raw, sfreq, segment_length):\n",
    "    data = raw.get_data()\n",
    "    n_channels, n_samples = data.shape\n",
    "    segment_samples = int(segment_length * sfreq)    \n",
    "    for ch in range(n_channels):\n",
    "        for start in range(0, n_samples, segment_samples):\n",
    "            end = min(start + segment_samples, n_samples)\n",
    "            segment = data[ch, start:end]\n",
    "            time = np.arange(start, end)\n",
    "            p = np.polyfit(time, segment, 1)\n",
    "            trend = np.polyval(p, time)\n",
    "            data[ch, start:end] -= trend    \n",
    "    raw._data = data\n",
    "    return raw\n",
    "\n",
    "def preprocess_fnirs_data(raw_data, proc_path, base):\n",
    "    raw_od = mne.preprocessing.nirs.optical_density(raw_data, verbose='error')\n",
    "\n",
    "    # Identify bad channels\n",
    "    peaks = np.ptp(raw_od.get_data('fnirs'), axis=-1)\n",
    "    flat_names = [raw_od.ch_names[f].split(' ')[0] for f in np.where(peaks < 0.001)[0]]\n",
    "    sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od)\n",
    "    sci_mask = (sci < 0.25)\n",
    "    got = np.where(sci_mask)[0]\n",
    "    percentage_bad = (len(got) / len(raw_od.ch_names)) * 100\n",
    "    print(f'    Run {base}')\n",
    "\n",
    "    # Assign bads\n",
    "    assert raw_od.info['bads'] == []\n",
    "    bads = set(raw_od.ch_names[pick] for pick in got)\n",
    "    bads = bads | set(ch_name for ch_name in raw_od.ch_names if ch_name.split(' ')[0] in flat_names)\n",
    "    bads = sorted(bads)\n",
    "\n",
    "    # Further preprocessing\n",
    "    raw_tddr = tddr(raw_od) # DON'T TDDR?\n",
    "    raw_tddr_bp = raw_tddr.copy().filter(**filt_kwargs) # DON'T BANDPASS FILTER?\n",
    "    #raw_tddr_bp = raw_od.copy() # Alternative Code\n",
    "    raw_tddr_bp.info['bads'] = bads\n",
    "    picks = mne.pick_types(raw_tddr_bp.info, fnirs=True)\n",
    "    peaks = np.ptp(raw_tddr_bp.get_data(picks), axis=-1)\n",
    "    assert (peaks > 1e-5).all()\n",
    "    raw_tddr_bp.info['bads'] = [] \n",
    "    raw_h = mne.preprocessing.nirs.beer_lambert_law(raw_tddr_bp, 6.)\n",
    "\n",
    "    # Normalize and verify bad channels\n",
    "    h_bads = [ch_name for ch_name in raw_h.ch_names if ch_name.split(' ')[0] in set(bad.split(' ')[0] for bad in bads)]\n",
    "    set_bads = set(bads)\n",
    "    set_h_bads = set(h_bads)\n",
    "    normalized_bads = normalize_channel_names(set_bads)\n",
    "    normalized_h_bads = normalize_channel_names(set_h_bads)\n",
    "    assert normalized_bads == normalized_h_bads\n",
    "    raw_h.info['bads'] = h_bads\n",
    "    raw_h.info._check_consistency()\n",
    "\n",
    "    # Further verification\n",
    "    picks = mne.pick_types(raw_h.info, fnirs=True)\n",
    "    peaks = np.ptp(raw_h.get_data(picks), axis=-1)\n",
    "    assert (peaks > 1e-9).all()\n",
    "\n",
    "    # Interpolate bad channels\n",
    "    raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n",
    "    raw_h_interp.save(op.join(proc_path, f'{base}_hbo_raw.fif'), overwrite=True)\n",
    "    assert len(raw_h.ch_names) == len(raw_h_interp.ch_names)\n",
    "\n",
    "    return raw_h_interp, percentage_bad, bads\n",
    "\n",
    "# Sanity check for subjects\n",
    "subjects_check = {int(subject) for subject in subjects}\n",
    "subject_to_group_check = set(subject_to_group.keys())\n",
    "if subjects_check == subject_to_group_check:\n",
    "    print(\"All done!\") \n",
    "    print(\"N=\" + str(len(subjects)))\n",
    "    del subjects_check\n",
    "    del subject_to_group_check\n",
    "else:\n",
    "    print(\"Error loading subject info\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove patients with over 30% bad channels on average across days and runs\n",
    "\n",
    "subjects_to_remove = ['202', '203', '204', '206', '214', '221', '223', '226', '233'] #201, 209?\n",
    "\n",
    "# Initialize counters for each group\n",
    "removed_trained = 0\n",
    "removed_control = 0\n",
    "\n",
    "remaining_trained = 0\n",
    "remaining_control = 0\n",
    "\n",
    "# Count and remove the subjects\n",
    "for subject in subjects_to_remove:\n",
    "    subject_int = int(subject)  # Convert to integer for dictionary key comparison\n",
    "    if subject_int in subject_to_group:\n",
    "        # Increment the appropriate counter based on the group of the subject\n",
    "        if subject_to_group[subject_int] == \"trained\":\n",
    "            removed_trained += 1\n",
    "        elif subject_to_group[subject_int] == \"control\":\n",
    "            removed_control += 1\n",
    "        # Remove the subject from the dictionary\n",
    "        subject_to_group.pop(subject_int, None)\n",
    "\n",
    "# Update the subjects list after counting the removed subjects\n",
    "subjects = [subject for subject in subjects if subject not in subjects_to_remove]\n",
    "\n",
    "for group in subject_to_group.values():\n",
    "    if group == \"trained\":\n",
    "        remaining_trained += 1\n",
    "    elif group == \"control\":\n",
    "        remaining_control += 1\n",
    "\n",
    "# Output the results\n",
    "print(f'Removed {removed_trained} trained subjects.')\n",
    "print(f'Removed {removed_control} control subjects.')\n",
    "print(f'Remaining trained subjects: {remaining_trained}')\n",
    "print(f'Remaining control subjects: {remaining_control}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Run 205_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.3s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Opening raw data file ../../processed/205_1_001_hbo_raw.fif...\n",
      "    Range : 0 ... 4171 =      0.000 ...   867.568 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Saved plot file!\n",
      "Loading ../../data/Day1/205_1/2023-10-13_002\n",
      "Reading 0 ... 4933  =      0.000 ...  1026.064 secs...\n",
      "    Run 205_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/205_3/2023-10-15_001\n",
      "Reading 0 ... 3864  =      0.000 ...   803.712 secs...\n",
      "    Run 205_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Opening raw data file ../../processed/205_3_001_hbo_raw.fif...\n",
      "    Range : 0 ... 3864 =      0.000 ...   803.712 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Saved plot file!\n",
      "Loading ../../data/Day3/205_3/2023-10-15_002\n",
      "Reading 0 ... 3943  =      0.000 ...   820.144 secs...\n",
      "    Run 205_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/207_1/2023-10-17_001\n",
      "Reading 0 ... 3929  =      0.000 ...   817.232 secs...\n",
      "    Run 207_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/207_1/2023-10-17_002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3958  =      0.000 ...   823.264 secs...\n",
      "    Run 207_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/207_3/2023-10-19_001\n",
      "Reading 0 ... 3927  =      0.000 ...   816.816 secs...\n",
      "    Run 207_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/207_3/2023-10-19_002\n",
      "Reading 0 ... 3941  =      0.000 ...   819.728 secs...\n",
      "    Run 207_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/208_1/2023-10-23_001\n",
      "Reading 0 ... 3941  =      0.000 ...   819.728 secs...\n",
      "    Run 208_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/208_1/2023-10-23_002\n",
      "Reading 0 ... 3931  =      0.000 ...   817.648 secs...\n",
      "    Run 208_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n",
      "Loading ../../data/Day3/208_3/2023-10-25_001\n",
      "Reading 0 ... 3971  =      0.000 ...   825.968 secs...\n",
      "    Run 208_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/208_3/2023-10-25_002\n",
      "Reading 0 ... 3726  =      0.000 ...   775.008 secs...\n",
      "    Run 208_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/209_1/2023-10-26_001\n",
      "Reading 0 ... 3966  =      0.000 ...   824.928 secs...\n",
      "    Run 209_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/209_1/2023-10-26_002\n",
      "Reading 0 ... 3965  =      0.000 ...   824.720 secs...\n",
      "    Run 209_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/209_3/2023-10-28_001\n",
      "Reading 0 ... 3965  =      0.000 ...   824.720 secs...\n",
      "    Run 209_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/209_3/2023-10-28_002\n",
      "Reading 0 ... 3941  =      0.000 ...   819.728 secs...\n",
      "    Run 209_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/212_1/2023-11-07_001\n",
      "Reading 0 ... 3946  =      0.000 ...   820.768 secs...\n",
      "    Run 212_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/212_1/2023-11-07_002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3941  =      0.000 ...   819.728 secs...\n",
      "    Run 212_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/212_3/2023-11-09_001\n",
      "Reading 0 ... 4047  =      0.000 ...   841.776 secs...\n",
      "    Run 212_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n",
      "Loading ../../data/Day3/212_3/2023-11-09_002\n",
      "Reading 0 ... 3973  =      0.000 ...   826.384 secs...\n",
      "    Run 212_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/213_1/2023-12-04_001\n",
      "Reading 0 ... 3972  =      0.000 ...   826.176 secs...\n",
      "    Run 213_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/213_1/2023-12-04_002\n",
      "Reading 0 ... 3951  =      0.000 ...   821.808 secs...\n",
      "    Run 213_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/213_3/2023-12-06_001\n",
      "Reading 0 ... 3989  =      0.000 ...   829.712 secs...\n",
      "    Run 213_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/213_3/2023-12-06_002\n",
      "Reading 0 ... 3974  =      0.000 ...   826.592 secs...\n",
      "    Run 213_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/215_1/2023-12-11_001\n",
      "Reading 0 ... 4361  =      0.000 ...   907.088 secs...\n",
      "    Run 215_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_001_long_hbo_raw.fif\n",
      "[done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../../data/Day1/215_1/2023-12-11_002\n",
      "Reading 0 ... 3923  =      0.000 ...   815.984 secs...\n",
      "    Run 215_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/215_3/2023-12-13_001\n",
      "Reading 0 ... 3934  =      0.000 ...   818.272 secs...\n",
      "    Run 215_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/215_3/2023-12-13_002\n",
      "Reading 0 ... 3975  =      0.000 ...   826.800 secs...\n",
      "    Run 215_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/216_1/2024-01-13_001\n",
      "Reading 0 ... 3936  =      0.000 ...   818.688 secs...\n",
      "    Run 216_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/216_1/2024-01-13_002\n",
      "Reading 0 ... 3931  =      0.000 ...   817.648 secs...\n",
      "    Run 216_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/216_3/2024-01-16_001\n",
      "Reading 0 ... 3940  =      0.000 ...   819.520 secs...\n",
      "    Run 216_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/216_3/2024-01-16_002\n",
      "Reading 0 ... 3927  =      0.000 ...   816.816 secs...\n",
      "    Run 216_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/217_1/2024-01-10_001\n",
      "Reading 0 ... 3930  =      0.000 ...   817.440 secs...\n",
      "    Run 217_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/217_1/2024-01-10_002\n",
      "Reading 0 ... 3943  =      0.000 ...   820.144 secs...\n",
      "    Run 217_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n",
      "Loading ../../data/Day3/217_3/2024-01-12_001\n",
      "Reading 0 ... 3922  =      0.000 ...   815.776 secs...\n",
      "    Run 217_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/217_3/2024-01-12_002\n",
      "Reading 0 ... 3946  =      0.000 ...   820.768 secs...\n",
      "    Run 217_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/218_1/2024-01-26_001\n",
      "Reading 0 ... 3968  =      0.000 ...   825.344 secs...\n",
      "    Run 218_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/218_1/2024-01-26_002\n",
      "Reading 0 ... 3953  =      0.000 ...   822.224 secs...\n",
      "    Run 218_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/218_3/2024-01-28_001\n",
      "Reading 0 ... 3951  =      0.000 ...   821.808 secs...\n",
      "    Run 218_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/218_3/2024-01-28_002\n",
      "Reading 0 ... 3931  =      0.000 ...   817.648 secs...\n",
      "    Run 218_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/219_1/2024-01-29_001\n",
      "Reading 0 ... 3969  =      0.000 ...   825.552 secs...\n",
      "    Run 219_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/219_1/2024-01-29_002\n",
      "Reading 0 ... 3924  =      0.000 ...   816.192 secs...\n",
      "    Run 219_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/219_3/2024-01-31_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3934  =      0.000 ...   818.272 secs...\n",
      "    Run 219_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/219_3/2024-01-31_002\n",
      "Reading 0 ... 3924  =      0.000 ...   816.192 secs...\n",
      "    Run 219_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.6 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/224_1/2024-02-10_001\n",
      "Reading 0 ... 3924  =      0.000 ...   816.192 secs...\n",
      "    Run 224_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/224_1/2024-02-10_002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3935  =      0.000 ...   818.480 secs...\n",
      "    Run 224_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_002_long_hbo_raw.fif\n",
      "[done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../../data/Day3/224_3/2024-02-12_001\n",
      "Reading 0 ... 3952  =      0.000 ...   822.016 secs...\n",
      "    Run 224_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/224_3/2024-02-12_002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3945  =      0.000 ...   820.560 secs...\n",
      "    Run 224_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/225_1/2024-04-29_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3942  =      0.000 ...   819.936 secs...\n",
      "    Run 225_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/225_1/2024-04-29_002\n",
      "Reading 0 ... 3939  =      0.000 ...   819.312 secs...\n",
      "    Run 225_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/225_3/2024-05-01_001\n",
      "Reading 0 ... 3945  =      0.000 ...   820.560 secs...\n",
      "    Run 225_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/225_3/2024-05-01_002\n",
      "Reading 0 ... 3943  =      0.000 ...   820.144 secs...\n",
      "    Run 225_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/228_1/2024-06-10_001\n",
      "Reading 0 ... 3978  =      0.000 ...   827.424 secs...\n",
      "    Run 228_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/228_1/2024-06-10_002\n",
      "Reading 0 ... 3978  =      0.000 ...   827.424 secs...\n",
      "    Run 228_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/228_3/2024-06-12_001\n",
      "Reading 0 ... 3992  =      0.000 ...   830.336 secs...\n",
      "    Run 228_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/228_3/2024-06-12_002\n",
      "Reading 0 ... 3954  =      0.000 ...   822.432 secs...\n",
      "    Run 228_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/229_1/2024-06-26_001\n",
      "Reading 0 ... 3956  =      0.000 ...   822.848 secs...\n",
      "    Run 229_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/229_1/2024-06-26_002\n",
      "Reading 0 ... 3968  =      0.000 ...   825.344 secs...\n",
      "    Run 229_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/229_3/2024-06-28_001\n",
      "Reading 0 ... 3945  =      0.000 ...   820.560 secs...\n",
      "    Run 229_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/229_3/2024-06-28_002\n",
      "Reading 0 ... 3934  =      0.000 ...   818.272 secs...\n",
      "    Run 229_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/230_1/2024-06-26_001\n",
      "Reading 0 ... 3941  =      0.000 ...   819.728 secs...\n",
      "    Run 230_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/230_1/2024-06-26_002\n",
      "Reading 0 ... 3925  =      0.000 ...   816.400 secs...\n",
      "    Run 230_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/230_3/2024-06-28_001\n",
      "Reading 0 ... 3986  =      0.000 ...   829.088 secs...\n",
      "    Run 230_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/230_3/2024-06-28_002\n",
      "Reading 0 ... 4007  =      0.000 ...   833.456 secs...\n",
      "    Run 230_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/231_1/2024-07-01_001\n",
      "Reading 0 ... 3927  =      0.000 ...   816.816 secs...\n",
      "    Run 231_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/231_1/2024-07-01_002\n",
      "Reading 0 ... 3937  =      0.000 ...   818.896 secs...\n",
      "    Run 231_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/231_3/2024-07-03_001\n",
      "Reading 0 ... 3930  =      0.000 ...   817.440 secs...\n",
      "    Run 231_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/231_3/2024-07-03_002\n",
      "Reading 0 ... 3949  =      0.000 ...   821.392 secs...\n",
      "    Run 231_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/232_1/2024-07-27_001\n",
      "Reading 0 ... 3944  =      0.000 ...   820.352 secs...\n",
      "    Run 232_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/232_1/2024-07-27_002\n",
      "Reading 0 ... 3935  =      0.000 ...   818.480 secs...\n",
      "    Run 232_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/232_3/2024-07-29_001\n",
      "Reading 0 ... 3942  =      0.000 ...   819.936 secs...\n",
      "    Run 232_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/232_3/2024-07-29_002\n",
      "Reading 0 ... 3946  =      0.000 ...   820.768 secs...\n",
      "    Run 232_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/234_1/2024-07-01_001\n",
      "Reading 0 ... 3964  =      0.000 ...   824.512 secs...\n",
      "    Run 234_1_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_001_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day1/234_1/2024-07-01_002\n",
      "Reading 0 ... 3938  =      0.000 ...   819.104 secs...\n",
      "    Run 234_1_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 93.7 mm\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_002_long_hbo_raw.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_002_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/234_3/2024-07-04_001\n",
      "Reading 0 ... 3883  =      0.000 ...   807.664 secs...\n",
      "    Run 234_3_001_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_001_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_001_long_hbo_raw.fif\n",
      "[done]\n",
      "Loading ../../data/Day3/234_3/2024-07-04_002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3956  =      0.000 ...   822.848 secs...\n",
      "    Run 234_3_002_long\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 0.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.20 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.20 Hz)\n",
      "- Filter length: 1587 samples (330.096 sec)\n",
      "\n",
      "Overwriting existing file.\n",
      "Writing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_002_long_hbo_raw.fif\n",
      "Closing /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_002_long_hbo_raw.fif\n",
      "[done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "/var/folders/dv/s4k5_3r51ml3q36bgbcdsgbr0000gn/T/ipykernel_42700/1216949861.py:161: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw_h_interp = raw_h.copy().interpolate_bads(reset_bads=True, method=dict(fnirs='nearest'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Load participant data\n",
    "\n",
    "#subjects = ('201 202').split() #for testing\n",
    "\n",
    "for subject in subjects:\n",
    "    for day in days:\n",
    "        for run in runs:\n",
    "            group = subject_to_group.get(int(subject), \"unknown\")\n",
    "            root1 = f'Day{day}'\n",
    "            root2 = f'{subject}_{day}'\n",
    "            root3 = f'*-*-*_{run:03d}'\n",
    "            fname_base = op.join(raw_path, root1, root2, root3)\n",
    "            fname = glob.glob(fname_base)\n",
    "            base = f'{subject}_{day}_{run:03d}'\n",
    "            base_pr = base.ljust(20)\n",
    "            # Save the plot subject\n",
    "            #if not op.isfile(op.join(proc_path, f'{base}_hbo_raw.fif')):\n",
    "            raw_intensity = mne.io.read_raw_nirx(fname[0])\n",
    "            long_chans = get_long_channels(raw_intensity)\n",
    "            raw_h_long, percentage_bad_long, bads_long = preprocess_fnirs_data(long_chans, proc_path, base + '_long')\n",
    "            add_bad_channel_entry(subject, day, run, percentage_bad_long)\n",
    "            del raw_intensity\n",
    "            if (op.isfile(op.join(proc_path, f'{base}_hbo_raw.fif')) and subject == plot_subject and run == plot_run):\n",
    "                fname2 = op.join(proc_path, f'{subject}_{day}_{run:03d}_hbo_raw.fif')\n",
    "                use = mne.io.read_raw_fif(fname2)\n",
    "                events, _ = mne.events_from_annotations(use)\n",
    "                ch_names = [ch_name.rstrip(' hbo') for ch_name in use.ch_names]\n",
    "                info = use.info\n",
    "                print(\"Saved plot file!\")\n",
    "\n",
    "print(\"All done!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Plot bad channels\n",
    " \n",
    "bad_channels_df = pd.read_csv(bad_channels_filename)\n",
    "bad_channels_df['Percent Bad'] = bad_channels_df['Percent Bad'].str.rstrip('%').astype(float)\n",
    "bad_channels_df['Subject'] = bad_channels_df['Subject'].astype(str)\n",
    "\n",
    "# Sort the DataFrame by percentage_bad in ascending order\n",
    "bad_channels_df = bad_channels_df.groupby('Subject')['Percent Bad'].mean().reset_index()\n",
    "bad_channels_df = bad_channels_df.sort_values(by='Percent Bad')\n",
    "bad_channels_df['Group'] = bad_channels_df['Subject'].map(lambda x: subject_to_group[int(x)])\n",
    "\n",
    "# Sort the DataFrame by Percent Bad in ascending order\n",
    "colors = bad_channels_df['Group'].map({'control': 'gray', 'trained': 'lightblue'})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(bad_channels_df['Subject'], bad_channels_df['Percent Bad'], color=colors)\n",
    "plt.axhline(30, color='red', linestyle='--')  # Horizontal line at 30%\n",
    "plt.xlabel('Subject', fontsize=14)\n",
    "plt.ylabel('Percent Bad', fontsize=14)\n",
    "plt.title('Percentage of Bad Channels per Participant', fontsize=14)\n",
    "plt.ylim(0, 100)  \n",
    "plt.yticks(np.arange(0, 101, 10), [f'{i}%' for i in np.arange(0, 101, 10)])\n",
    "\n",
    "output_filename = op.join(results_path, 'bad_channels_report.png')\n",
    "plt.savefig(output_filename, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../../processed/201_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3994 =      0.000 ...   830.752 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/201_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3838 =      0.000 ...   798.304 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/201_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/201_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4171 =      0.000 ...   867.568 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4933 =      0.000 ...  1026.064 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3864 =      0.000 ...   803.712 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3929 =      0.000 ...   817.232 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '255.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3958 =      0.000 ...   823.264 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3971 =      0.000 ...   825.968 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3726 =      0.000 ...   775.008 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3966 =      0.000 ...   824.928 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3965 =      0.000 ...   824.720 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3965 =      0.000 ...   824.720 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4047 =      0.000 ...   841.776 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3973 =      0.000 ...   826.384 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3972 =      0.000 ...   826.176 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3951 =      0.000 ...   821.808 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3989 =      0.000 ...   829.712 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3974 =      0.000 ...   826.592 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4361 =      0.000 ...   907.088 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3923 =      0.000 ...   815.984 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3975 =      0.000 ...   826.800 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3936 =      0.000 ...   818.688 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3940 =      0.000 ...   819.520 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3930 =      0.000 ...   817.440 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3922 =      0.000 ...   815.776 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3968 =      0.000 ...   825.344 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3953 =      0.000 ...   822.224 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3951 =      0.000 ...   821.808 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3969 =      0.000 ...   825.552 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3935 =      0.000 ...   818.480 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3952 =      0.000 ...   822.016 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3942 =      0.000 ...   819.936 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3939 =      0.000 ...   819.312 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3978 =      0.000 ...   827.424 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3978 =      0.000 ...   827.424 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3992 =      0.000 ...   830.336 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3954 =      0.000 ...   822.432 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3956 =      0.000 ...   822.848 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3968 =      0.000 ...   825.344 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3925 =      0.000 ...   816.400 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3986 =      0.000 ...   829.088 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4007 =      0.000 ...   833.456 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3937 =      0.000 ...   818.896 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3930 =      0.000 ...   817.440 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3949 =      0.000 ...   821.392 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3944 =      0.000 ...   820.352 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3935 =      0.000 ...   818.480 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3942 =      0.000 ...   819.936 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3964 =      0.000 ...   824.512 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3938 =      0.000 ...   819.104 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3883 =      0.000 ...   807.664 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3956 =      0.000 ...   822.848 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Define make_design\n",
    "\n",
    "sfreq = 4.807692\n",
    "\n",
    "for subject in subjects:\n",
    "    for day in days:\n",
    "        for run in runs:\n",
    "            fname = op.join(proc_path, f'{subject}_{day}_{run:03d}_long_hbo_raw.fif')\n",
    "            raw_h = mne.io.read_raw_fif(fname)\n",
    "            events, _ = mne.events_from_annotations(raw_h)\n",
    "            #print(len(events))\n",
    "\n",
    "print(\"All done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjects = ('224 225 226 228 229 230 231 232 233 234').split() #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../../processed/201_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3994 =      0.000 ...   830.752 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/201_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3838 =      0.000 ...   798.304 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 201 day 1.\n",
      "Opening raw data file ../../processed/201_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/201_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 201 day 3.\n",
      "Opening raw data file ../../processed/205_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4171 =      0.000 ...   867.568 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4933 =      0.000 ...  1026.064 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 205 day 1.\n",
      "Opening raw data file ../../processed/205_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3864 =      0.000 ...   803.712 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 205 day 3.\n",
      "Opening raw data file ../../processed/207_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3929 =      0.000 ...   817.232 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3958 =      0.000 ...   823.264 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 207 day 1.\n",
      "Opening raw data file ../../processed/207_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 207 day 3.\n",
      "Opening raw data file ../../processed/208_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 208 day 1.\n",
      "Opening raw data file ../../processed/208_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3971 =      0.000 ...   825.968 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3726 =      0.000 ...   775.008 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 208 day 3.\n",
      "Opening raw data file ../../processed/209_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3966 =      0.000 ...   824.928 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3965 =      0.000 ...   824.720 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 209 day 1.\n",
      "Opening raw data file ../../processed/209_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3965 =      0.000 ...   824.720 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 209 day 3.\n",
      "Opening raw data file ../../processed/212_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 212 day 1.\n",
      "Opening raw data file ../../processed/212_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4047 =      0.000 ...   841.776 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3973 =      0.000 ...   826.384 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 212 day 3.\n",
      "Opening raw data file ../../processed/213_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3972 =      0.000 ...   826.176 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3951 =      0.000 ...   821.808 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 213 day 1.\n",
      "Opening raw data file ../../processed/213_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3989 =      0.000 ...   829.712 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3974 =      0.000 ...   826.592 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 213 day 3.\n",
      "Opening raw data file ../../processed/215_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4361 =      0.000 ...   907.088 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3923 =      0.000 ...   815.984 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 215 day 1.\n",
      "Opening raw data file ../../processed/215_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3975 =      0.000 ...   826.800 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 215 day 3.\n",
      "Opening raw data file ../../processed/216_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3936 =      0.000 ...   818.688 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 216 day 1.\n",
      "Opening raw data file ../../processed/216_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3940 =      0.000 ...   819.520 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 216 day 3.\n",
      "Opening raw data file ../../processed/217_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3930 =      0.000 ...   817.440 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 217 day 1.\n",
      "Opening raw data file ../../processed/217_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3922 =      0.000 ...   815.776 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 217 day 3.\n",
      "Opening raw data file ../../processed/218_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3968 =      0.000 ...   825.344 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3953 =      0.000 ...   822.224 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 218 day 1.\n",
      "Opening raw data file ../../processed/218_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3951 =      0.000 ...   821.808 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 218 day 3.\n",
      "Opening raw data file ../../processed/219_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3969 =      0.000 ...   825.552 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 219 day 1.\n",
      "Opening raw data file ../../processed/219_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 219 day 3.\n",
      "Opening raw data file ../../processed/224_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3935 =      0.000 ...   818.480 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 224 day 1.\n",
      "Opening raw data file ../../processed/224_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3952 =      0.000 ...   822.016 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 224 day 3.\n",
      "Opening raw data file ../../processed/225_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3942 =      0.000 ...   819.936 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3939 =      0.000 ...   819.312 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 225 day 1.\n",
      "Opening raw data file ../../processed/225_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 225 day 3.\n",
      "Opening raw data file ../../processed/228_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3978 =      0.000 ...   827.424 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3978 =      0.000 ...   827.424 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 228 day 1.\n",
      "Opening raw data file ../../processed/228_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3992 =      0.000 ...   830.336 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3954 =      0.000 ...   822.432 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 228 day 3.\n",
      "Opening raw data file ../../processed/229_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3956 =      0.000 ...   822.848 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3968 =      0.000 ...   825.344 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 229 day 1.\n",
      "Opening raw data file ../../processed/229_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 229 day 3.\n",
      "Opening raw data file ../../processed/230_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3925 =      0.000 ...   816.400 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 230 day 1.\n",
      "Opening raw data file ../../processed/230_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3986 =      0.000 ...   829.088 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4007 =      0.000 ...   833.456 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 230 day 3.\n",
      "Opening raw data file ../../processed/231_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3937 =      0.000 ...   818.896 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 231 day 1.\n",
      "Opening raw data file ../../processed/231_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3930 =      0.000 ...   817.440 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3949 =      0.000 ...   821.392 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 231 day 3.\n",
      "Opening raw data file ../../processed/232_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3944 =      0.000 ...   820.352 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3935 =      0.000 ...   818.480 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 232 day 1.\n",
      "Opening raw data file ../../processed/232_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3942 =      0.000 ...   819.936 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 232 day 3.\n",
      "Opening raw data file ../../processed/234_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3964 =      0.000 ...   824.512 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3938 =      0.000 ...   819.104 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 234 day 1.\n",
      "Opening raw data file ../../processed/234_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3883 =      0.000 ...   807.664 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3956 =      0.000 ...   822.848 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "***Finished processing subject 234 day 3.\n",
      "Finished processing all subjects.\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Run GLM analysis and epoching\n",
    "\n",
    "sfreq = 4.807692050933838\n",
    "\n",
    "subj_cha_list = []\n",
    "for subject in subjects:\n",
    "    group = subject_to_group.get(int(subject), \"unknown\")\n",
    "    \n",
    "    for day in days:\n",
    "        for run in runs:\n",
    "            fname_long = op.join(proc_path, f'{subject}_{day}_{run:03d}_long_hbo_raw.fif')\n",
    "            raw_h_long = mne.io.read_raw_fif(fname_long)\n",
    "            _, dm, _ = _make_design(raw_h_long, design, subject, run, day, group)\n",
    "            glm_est = mne_nirs.statistics.run_glm(\n",
    "                raw_h_long, dm, noise_model='ols', n_jobs=n_jobs)\n",
    "            cha = glm_est.to_dataframe()\n",
    "            cha['subject'] = subject\n",
    "            cha['run'] = run\n",
    "            cha['day'] = day\n",
    "            cha['group'] = group\n",
    "            subj_cha_list.append(cha)\n",
    "            del raw_h_long\n",
    "        print(f'***Finished processing subject {subject} day {day}.')\n",
    "\n",
    "df_cha = pd.concat(subj_cha_list, ignore_index=True)\n",
    "df_cha.reset_index(drop=True, inplace=True)\n",
    "print(\"Finished processing all subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "def _make_design(raw_h_long, design, subject=None, run=None, day=None, group=None):\n",
    "    annotations_to_remove = raw_h_long.annotations.description == '255.0'\n",
    "    raw_h_long.annotations.delete(annotations_to_remove)\n",
    "    events, _ = mne.events_from_annotations(raw_h_long)\n",
    "    rows_to_remove = events[:, -1] == 1\n",
    "    events = events[~rows_to_remove]\n",
    "    \n",
    "    # Mis-codings\n",
    "    if len(events) == 101:\n",
    "        events = events[1:]\n",
    "        \n",
    "    n_times = len(raw_h_long.times)\n",
    "    stim = np.zeros((n_times, 4))\n",
    "    events[:, 2] -= 1\n",
    "    assert len(events) == 100, len(events)\n",
    "    want = [0] + [25] * 4\n",
    "    count = np.bincount(events[:, 2])\n",
    "    assert np.array_equal(count, want), count\n",
    "    assert events.shape == (100, 3), events.shape\n",
    "    if design == 'block':\n",
    "        events = events[0::5]\n",
    "        duration = 20.\n",
    "        assert np.array_equal(np.bincount(events[:, 2]), [0] + [5] * 4)\n",
    "    else:\n",
    "#        assert design == 'event'\n",
    "        assert len(events) == 100\n",
    "        duration = 1.8\n",
    "        assert events.shape == (100, 3)\n",
    "        events_r = events[:, 2].reshape(20, 5)\n",
    "        assert (events_r == events_r[:, :1]).all()\n",
    "        del events_r\n",
    "        \n",
    "    idx = (events[:, [0, 2]] - [0, 1]).T\n",
    "    assert np.in1d(idx[1], np.arange(len(conditions))).all()\n",
    "    stim[tuple(idx)] = 1\n",
    "    \n",
    "    # assert raw_h.info['sfreq'] == sfreq  # necessary for below logic to work\n",
    "    n_block = int(np.ceil(duration * sfreq))\n",
    "    stim = signal.fftconvolve(stim, np.ones((n_block, 1)), axes=0)[:n_times]\n",
    "    dm_events = pd.DataFrame({\n",
    "        'trial_type': [conditions[ii] for ii in idx[1]],\n",
    "        'onset': idx[0] / raw_h_long.info['sfreq'],\n",
    "        'duration': n_block / raw_h_long.info['sfreq']})\n",
    "    dm = make_first_level_design_matrix(\n",
    "        raw_h_long.times, dm_events, hrf_model='glover',\n",
    "        drift_model='polynomial', drift_order=0)\n",
    "        \n",
    "    return stim, dm, events\n",
    "\n",
    "print(\"All done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To skip above block, just run this:\n",
    "#df_cha = pd.read_csv(op.join(results_path, 'df_cha_theta.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating block average for 201 day 1... Opening raw data file ../../processed/201_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3994 =      0.000 ...   830.752 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/201_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3838 =      0.000 ...   798.304 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.8 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 201 day 1 run 002... Creating block average for 205 day 1... Opening raw data file ../../processed/205_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4171 =      0.000 ...   867.568 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4933 =      0.000 ...  1026.064 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.7 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 205 day 1 run 002... Creating block average for 207 day 1... Opening raw data file ../../processed/207_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3929 =      0.000 ...   817.232 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3958 =      0.000 ...   823.264 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 207 day 1 run 002... Creating block average for 208 day 1... Opening raw data file ../../processed/208_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 208 day 1 run 002... Creating block average for 209 day 1... Opening raw data file ../../processed/209_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3966 =      0.000 ...   824.928 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3965 =      0.000 ...   824.720 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.8 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 209 day 1 run 002... Creating block average for 212 day 1... Opening raw data file ../../processed/212_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.1 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 212 day 1 run 002... Creating block average for 213 day 1... Opening raw data file ../../processed/213_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3972 =      0.000 ...   826.176 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3951 =      0.000 ...   821.808 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.2 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 213 day 1 run 002... Creating block average for 215 day 1... Opening raw data file ../../processed/215_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4361 =      0.000 ...   907.088 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3923 =      0.000 ...   815.984 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.3 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 215 day 1 run 002... Creating block average for 216 day 1... Opening raw data file ../../processed/216_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3936 =      0.000 ...   818.688 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.9 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 216 day 1 run 002... Creating block average for 217 day 1... Opening raw data file ../../processed/217_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3930 =      0.000 ...   817.440 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 217 day 1 run 002... Creating block average for 218 day 1... Opening raw data file ../../processed/218_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3968 =      0.000 ...   825.344 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3953 =      0.000 ...   822.224 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.8 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 218 day 1 run 002... Creating block average for 219 day 1... Opening raw data file ../../processed/219_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3969 =      0.000 ...   825.552 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.9 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 219 day 1 run 002... Creating block average for 224 day 1... Opening raw data file ../../processed/224_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3935 =      0.000 ...   818.480 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 224 day 1 run 002... Creating block average for 225 day 1... Opening raw data file ../../processed/225_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3942 =      0.000 ...   819.936 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3939 =      0.000 ...   819.312 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "6.1 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 225 day 1 run 002... Creating block average for 228 day 1... Opening raw data file ../../processed/228_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3978 =      0.000 ...   827.424 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3978 =      0.000 ...   827.424 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "5.1 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 228 day 1 run 002... Creating block average for 229 day 1... Opening raw data file ../../processed/229_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3956 =      0.000 ...   822.848 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3968 =      0.000 ...   825.344 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.1 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 229 day 1 run 002... Creating block average for 230 day 1... Opening raw data file ../../processed/230_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3925 =      0.000 ...   816.400 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 230 day 1 run 002... Creating block average for 231 day 1... Opening raw data file ../../processed/231_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3937 =      0.000 ...   818.896 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.9 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 231 day 1 run 002... Creating block average for 232 day 1... Opening raw data file ../../processed/232_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3944 =      0.000 ...   820.352 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3935 =      0.000 ...   818.480 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 232 day 1 run 002... Creating block average for 234 day 1... Opening raw data file ../../processed/234_1_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3964 =      0.000 ...   824.512 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_1_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3938 =      0.000 ...   819.104 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_1_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 234 day 1 run 002... Creating block average for 201 day 3... Opening raw data file ../../processed/201_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/201_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/201_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 201 day 3 run 002... Creating block average for 205 day 3... Opening raw data file ../../processed/205_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3864 =      0.000 ...   803.712 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/205_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.1 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/205_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 205 day 3 run 002... Creating block average for 207 day 3... Opening raw data file ../../processed/207_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/207_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/207_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 207 day 3 run 002... Creating block average for 208 day 3... Opening raw data file ../../processed/208_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3971 =      0.000 ...   825.968 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/208_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3726 =      0.000 ...   775.008 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.5 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/208_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 208 day 3 run 002... Creating block average for 209 day 3... Opening raw data file ../../processed/209_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3965 =      0.000 ...   824.720 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/209_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3941 =      0.000 ...   819.728 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/209_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 209 day 3 run 002... Creating block average for 212 day 3... Opening raw data file ../../processed/212_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4047 =      0.000 ...   841.776 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/212_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3973 =      0.000 ...   826.384 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.9 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/212_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 212 day 3 run 002... Creating block average for 213 day 3... Opening raw data file ../../processed/213_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3989 =      0.000 ...   829.712 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/213_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3974 =      0.000 ...   826.592 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.7 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/213_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 213 day 3 run 002... Creating block average for 215 day 3... Opening raw data file ../../processed/215_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/215_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3975 =      0.000 ...   826.800 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "5.0 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/215_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 215 day 3 run 002... Creating block average for 216 day 3... Opening raw data file ../../processed/216_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3940 =      0.000 ...   819.520 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/216_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3927 =      0.000 ...   816.816 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.7 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/216_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 216 day 3 run 002... Creating block average for 217 day 3... Opening raw data file ../../processed/217_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3922 =      0.000 ...   815.776 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/217_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "4.4 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/217_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 217 day 3 run 002... Creating block average for 218 day 3... Opening raw data file ../../processed/218_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3951 =      0.000 ...   821.808 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/218_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3931 =      0.000 ...   817.648 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.7 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/218_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 218 day 3 run 002... Creating block average for 219 day 3... Opening raw data file ../../processed/219_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/219_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3924 =      0.000 ...   816.192 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.5 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/219_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 219 day 3 run 002... Creating block average for 224 day 3... Opening raw data file ../../processed/224_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3952 =      0.000 ...   822.016 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/224_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/224_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 224 day 3 run 002... Creating block average for 225 day 3... Opening raw data file ../../processed/225_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/225_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3943 =      0.000 ...   820.144 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.5 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/225_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 225 day 3 run 002... Creating block average for 228 day 3... Opening raw data file ../../processed/228_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3992 =      0.000 ...   830.336 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/228_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3954 =      0.000 ...   822.432 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.8 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/228_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 228 day 3 run 002... Creating block average for 229 day 3... Opening raw data file ../../processed/229_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3945 =      0.000 ...   820.560 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/229_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3934 =      0.000 ...   818.272 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.5 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/229_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 229 day 3 run 002... Creating block average for 230 day 3... Opening raw data file ../../processed/230_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3986 =      0.000 ...   829.088 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/230_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 4007 =      0.000 ...   833.456 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.6 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/230_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 230 day 3 run 002... Creating block average for 231 day 3... Opening raw data file ../../processed/231_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3930 =      0.000 ...   817.440 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/231_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3949 =      0.000 ...   821.392 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.5 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/231_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 231 day 3 run 002... Creating block average for 232 day 3... Opening raw data file ../../processed/232_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3942 =      0.000 ...   819.936 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/232_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3946 =      0.000 ...   820.768 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.5 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/232_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 232 day 3 run 002... Creating block average for 234 day 3... Opening raw data file ../../processed/234_3_001_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3883 =      0.000 ...   807.664 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Opening raw data file ../../processed/234_3_002_long_hbo_raw.fif...\n",
      "    Range : 0 ... 3956 =      0.000 ...   822.848 secs\n",
      "Ready.\n",
      "Used Annotations descriptions: ['1.0', '2.0', '3.0', '4.0', '5.0']\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Setting baseline interval to [-2.0800001110839905, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Overwriting existing file.\n",
      "3.5 sec\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (A)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (V)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (AV)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Reading /Users/ansle/Documents/GitHub/fnirs-analysis/GithubCode/fnirs-analysis/../../processed/234_3_av-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2080.00 ...   38064.00 ms (W)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-2.08, 0] sec)\n",
      "Done for control 234 day 3 run 002... All done!\n"
     ]
    }
   ],
   "source": [
    "# Block averages\n",
    "event_id = {condition: ci for ci, condition in enumerate(conditions, 1)}\n",
    "evokeds = {condition: dict() for condition in conditions}\n",
    "for day in days:\n",
    "    for subject in subjects:\n",
    "        fname = op.join(proc_path, f'{subject}_{day}_{exp_name}-ave.fif')\n",
    "#        if not op.isfile(fname):\n",
    "        tmin, tmax = -2, 38\n",
    "        baseline = (None, 0)\n",
    "        t0 = time.time()\n",
    "        print(f'Creating block average for {subject} day {day}... ', end='')\n",
    "        raws = list()\n",
    "        events = list()\n",
    "        for run in runs:\n",
    "            fname2 = op.join(proc_path, f'{subject}_{day}_{run:03d}_long_hbo_raw.fif')\n",
    "            raw_h = mne.io.read_raw_fif(fname2)\n",
    "            events.append(_make_design(raw_h, None, 'block', subject, run)[2])\n",
    "            raws.append(raw_h)\n",
    "        bads = sorted(set(sum((r.info['bads'] for r in raws), [])))\n",
    "        for r in raws:\n",
    "            r.info['bads'] = bads\n",
    "        raw_h, events = mne.concatenate_raws(raws, events_list=events)\n",
    "        epochs = mne.Epochs(raw_h, events, event_id, tmin=tmin, tmax=tmax,\n",
    "                            baseline=baseline)\n",
    "        this_ev = [epochs[condition].average() for condition in conditions]\n",
    "        assert all(ev.nave > 0 for ev in this_ev)\n",
    "        mne.write_evokeds(fname, this_ev, overwrite=True)\n",
    "        print(f'{time.time() - t0:0.1f} sec')\n",
    "        for condition in conditions:\n",
    "            evokeds[condition][subject] = mne.read_evokeds(fname, condition)\n",
    "        print(f'Done for {group} {subject} day {day} run {run:03d}... ', end='')\n",
    "\n",
    "\n",
    "# Mark bad channels\n",
    "bad = dict()\n",
    "bb = dict()\n",
    "\n",
    "for day in days:\n",
    "    for subject in subjects:\n",
    "        for run in runs:\n",
    "            fname2 = op.join(proc_path, f'{subject}_{day}_{run:03d}_long_hbo_raw.fif')\n",
    "            this_info = mne.io.read_info(fname2)\n",
    "            bad_channels = [idx - 1 for idx in sorted(\n",
    "                this_info['ch_names'].index(bad) + 1 for bad in this_info['bads'])]\n",
    "            valid_indices = np.arange(len(use.ch_names))\n",
    "            bb = [b for b in bad_channels if b in valid_indices]\n",
    "            bad[(subject, run, day)] = bb\n",
    "        assert np.in1d(bad[(subject, run, day)], np.arange(len(use.ch_names))).all()  # noqa: E501\n",
    "\n",
    "bad_combo = dict()\n",
    "for day in days:\n",
    "    for (subject, run, day), bb in bad_channels:\n",
    "        bad_combo[subject] = sorted(set(bad_combo.get(subject, [])) | set(bb))\n",
    "bad = bad_combo\n",
    "#assert set(bad) == set(subjects)\n",
    "\n",
    "start = len(df_cha)\n",
    "n_drop = 0\n",
    "for day in days:\n",
    "    for (subject, run, day), bb in bad_channels:\n",
    "        if not len(bb):\n",
    "            continue\n",
    "        drop_names = [use.ch_names[b] for b in bb]\n",
    "        is_subject = (df_cha['subject'] == subject)\n",
    "        is_day = (df_cha['day'] == day)\n",
    "        assert len(is_subject) == len(df_cha)\n",
    "        is_day = (df_cha['day'] == day)\n",
    "        drop = df_cha.index[\n",
    "            is_subject &\n",
    "            is_day &\n",
    "            np.in1d(df_cha['ch_name'], drop_names)]\n",
    "        n_drop += len(drop)\n",
    "        if len(drop):\n",
    "            print(f'Dropping {len(drop)} for {subject} day {day}')  # {run}')\n",
    "            df_cha.drop(drop, inplace=True)\n",
    "end = len(df_cha)\n",
    "assert n_drop == start - end, (n_drop, start - end)\n",
    "\n",
    "# Combine runs by averaging\n",
    "sorts = ['subject', 'ch_name', 'Chroma', 'Condition', 'group', 'day', 'run']\n",
    "df_cha.sort_values(\n",
    "    sorts, inplace=True)\n",
    "theta = np.array(df_cha['theta']).reshape(-1, len(runs)).mean(-1)\n",
    "df_cha.drop(\n",
    "    [col for col in df_cha.columns if col not in sorts[:-1]], axis='columns',\n",
    "    inplace=True)\n",
    "df_cha.reset_index(drop=True, inplace=True)\n",
    "df_cha = df_cha[::len(runs)]\n",
    "df_cha.reset_index(drop=True, inplace=True)\n",
    "df_cha['theta'] = theta\n",
    "df_cha.to_csv(op.join(results_path, 'df_cha_theta_tddr_bp.csv'), index=False)\n",
    "\n",
    "print(\"All done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR CHANNEL x CONDITION ANALYSIS ONLY\n",
    "\n",
    "# Mixed linear model\n",
    "def _mixed_df(ch_summary):\n",
    "    formula = \"theta ~ -1 + ch_name:Condition\" \n",
    "    ch_model = smf.mixedlm(\n",
    "        formula, ch_summary, groups=ch_summary[\"subject\"]).fit(method='powell')\n",
    "    ch_model_df = mne_nirs.statistics.statsmodels_to_results(ch_model)\n",
    "    ch_model_df['P>|z|'] = ch_model.pvalues\n",
    "    ch_model_df.drop([idx for idx in ch_model_df.index if '[constant]' in idx],\n",
    "                    inplace=True)\n",
    "    return ch_model_df\n",
    "\n",
    "print(\"All done!\") \n",
    "\n",
    "# Make separate subject lists for trained and untrained (TEST)\n",
    "#trained_subjects = {'201 203 207 212 213 214 216 219 221 223'}\n",
    "#control_subjects = {'202 204 205 206 208 209 215 217 218 224'}\n",
    "\n",
    "# Run group level model and convert to dataframe\n",
    "ch_summary = df_cha.query(\"Chroma in ['hbo']\").copy()   ### ALSO RUN HBR ANALYSIS\n",
    "#ch_summary = df_cha.query(\"Chroma in ['hbo'] and group in ['trained'] and day in ['3']\").copy()\n",
    "ch_model_df = _mixed_df(ch_summary) \n",
    "ch_model_df.reset_index(inplace=True)\n",
    "\n",
    "# Correct for multiple comparisons\n",
    "print(f'Correcting for {len(ch_model_df[\"P>|z|\"])} comparisons using FDR')\n",
    "_, ch_model_df['P_fdr'] = mne.stats.fdr_correction(\n",
    "    ch_model_df['P>|z|'], method='indep')\n",
    "ch_model_df['SIG'] = ch_model_df['P_fdr'] < 0.05\n",
    "ch_model_df.to_csv(op.join(results_path, 'ch_model_corrected_hbo.csv'), index=False)\n",
    "ch_model_df.loc[ch_model_df.SIG == True]\n",
    "\n",
    "print(\"All done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################\n",
    "# # Plot significant channels\n",
    "\n",
    "# sig_chs = dict()\n",
    "# zs = dict()\n",
    "# for condition in conditions:\n",
    "#     sig_df = ch_model_df[\n",
    "#         (ch_model_df['P_fdr'] < 0.05) &\n",
    "#         (ch_model_df['Condition'] == condition) &\n",
    "#         (ch_model_df['ch_name'].isin(use.ch_names))\n",
    "#         ]\n",
    "#     sig_chs[(condition)] = sorted(\n",
    "#         (use.ch_names.index(row[1]['ch_name']), row[1]['P_fdr'])\n",
    "#         for row in sig_df.iterrows())\n",
    "#     ch_model_df[ch_model_df['Condition'] == condition]\n",
    "#     zs[condition] = np.array([\n",
    "#         ch_model_df.loc[(ch_model_df['Condition'] == condition) & \n",
    "#                         (ch_model_df['ch_name'] == ch_name), 'z'].iloc[0]\n",
    "#         for ch_name in info['ch_names'][::2]], float)\n",
    "#     assert zs[condition].shape == (84,)\n",
    "#     assert np.isfinite(zs[condition]).all()\n",
    "\n",
    "# def _plot_sig_chs(sigs, ax):\n",
    "#     if sigs and isinstance(sigs[0], tuple):\n",
    "#         sigs = [s[0] for s in sigs]\n",
    "#     ch_groups = [sigs, np.setdiff1d(np.arange(info['nchan']), sigs)]\n",
    "#     mne.viz.plot_sensors(\n",
    "#         info, 'topomap', 'hbo', title='', axes=ax,\n",
    "#         show_names=True, ch_groups=ch_groups)\n",
    "#     ax.collections[0].set(lw=0)\n",
    "#     c = ax.collections[0].get_facecolor()\n",
    "#     c[(c[:, :3] == (0.5, 0, 0)).all(-1)] = (0., 0., 0., 0.1)\n",
    "#     c[(c[:, :3] == (0, 0, 0.5)).all(-1)] = (0., 1., 0., 0.5)\n",
    "#     ax.collections[0].set_facecolor(c)\n",
    "#     ch_names = [info['ch_names'][idx] for idx in sigs]\n",
    "#     texts = list(ax.texts)\n",
    "#     got = []\n",
    "#     for text in list(texts):\n",
    "#         try:\n",
    "#             idx = ch_names.index(text.get_text())\n",
    "#         except ValueError:\n",
    "#             text.remove()\n",
    "#         else:\n",
    "#             got.append(idx)\n",
    "#             text.set_text(f'{sigs[idx] // 2 + 1}')\n",
    "#             text.set(fontsize='xx-small', zorder=5, ha='center')\n",
    "#     assert len(got) == len(sigs), (got, list(sigs))\n",
    "\n",
    "# def _plot_sigs(sig_chs, all_corrs=()):\n",
    "#     n_col = max(len(x) for x in sig_chs.values()) + 1\n",
    "#     n_row = len(conditions)\n",
    "#     figsize = (n_col * 1.0, n_row * 1.0)\n",
    "#     fig, axes = plt.subplots(\n",
    "#         n_row, n_col, figsize=figsize, constrained_layout=True, squeeze=False)\n",
    "#     h_colors = {0: 'r', 1: 'b'}\n",
    "#     xticks = [0, 10, 20, 30]\n",
    "#     ylim = [-0.2, 0.3]\n",
    "#     yticks = [-0.2, -0.1, 0, 0.1, 0.2, 0.3]\n",
    "#     xlim = [times[0], 35]\n",
    "#     ylim = np.array(ylim)\n",
    "#     yticks = np.array(yticks)\n",
    "#     for ci, condition in enumerate(conditions):\n",
    "#         ii = 0\n",
    "#         sigs = sig_chs[condition]\n",
    "#         if len(sigs) == 0:\n",
    "#             sigs = [(None, None)]\n",
    "#         for ii, (ch_idx, ch_p) in enumerate(sigs):\n",
    "#             ax = axes[ci, ii]\n",
    "#             if ch_idx is not None:\n",
    "#                 for jj in range(2):  # HbO, HbR\n",
    "#                     color = h_colors[jj]\n",
    "#                     a = 1e6 * np.array(\n",
    "#                         [evokeds[condition][subject].data[ch_idx + jj]\n",
    "#                          for subject in use_subjects\n",
    "#                          if ch_idx + jj not in bad.get(subject, [])], float)\n",
    "#                     m = np.mean(a, axis=0)\n",
    "#                     lower, upper = stats.t.interval(\n",
    "#                         0.95, len(a) - 1, loc=m, scale=stats.sem(a, axis=0))\n",
    "#                     ax.fill_between(\n",
    "#                         times, lower, upper, facecolor=color,\n",
    "#                         edgecolor='none', lw=0, alpha=0.25, zorder=3,\n",
    "#                         clip_on=False)\n",
    "#                     ax.plot(times, m, color=color, lw=1, zorder=4,\n",
    "#                             clip_on=False)\n",
    "#                 # Correlations\n",
    "#                 this_df = ch_summary_use.query(\n",
    "#                     f'ch_name == {repr(use.ch_names[ch_idx])} and '\n",
    "#                     f'Chroma == \"hbo\" and '\n",
    "#                     f'Condition == {repr(condition)}')\n",
    "#                 #assert 8 <= len(this_df) <= len(subjects), len(this_df)\n",
    "#                 a = np.array(this_df['theta'])\n",
    "#                 cs = list()\n",
    "#                 if len(cs):\n",
    "#                     cs = [''] + cs\n",
    "#                 c = '\\n'.join(cs)\n",
    "#                 ax.text(times[-1], ylim[1],\n",
    "#                         f'ch{ch_idx // 2 + 1}\\np={ch_p:0.5f}{c}',\n",
    "#                         ha='right', va='top', fontsize='x-small')\n",
    "#             ax.axvline(20, ls=':', color='0.5', zorder=2, lw=1)\n",
    "#             ax.axhline(0, ls='-', color='k', zorder=2, lw=0.5)\n",
    "#             ax.set(xticks=xticks, yticks=yticks)\n",
    "#             ax.set(xlim=xlim, ylim=ylim)\n",
    "#             for key in ('top', 'right'):\n",
    "#                 ax.spines[key].set_visible(False)\n",
    "#             if ax.get_subplotspec().is_last_row():\n",
    "#                 ax.set(xlabel='Time (sec)')\n",
    "#             else:\n",
    "#                 ax.set_xticklabels([''] * len(xticks))\n",
    "#             if ax.get_subplotspec().is_first_col():\n",
    "#                 ax.set_ylabel(condition)\n",
    "#             else:\n",
    "#                 ax.set_yticklabels([''] * len(yticks))\n",
    "#             for key in ('top', 'right'):\n",
    "#                 ax.spines[key].set_visible(False)\n",
    "#         for ii in range(ii + 1, n_col - 1):\n",
    "#             fig.delaxes(axes[ci, ii])\n",
    "#         # montage\n",
    "#         ax = axes[ci, -1]\n",
    "#         if sigs[0][0] is None:\n",
    "#             fig.delaxes(ax)\n",
    "#         else:\n",
    "#             # plot montage\n",
    "#             _plot_sig_chs(sigs, ax)\n",
    "#     return fig\n",
    "\n",
    "# times = evokeds[conditions[0]][subjects[0]].times\n",
    "# info = evokeds[conditions[0]][subjects[0]].info\n",
    "# fig = _plot_sigs(sig_chs)\n",
    "# for ext in ('png', 'svg'):\n",
    "#     fig.savefig(op.join(results_path, f'stats_{exp_name}.{ext}'))\n",
    "\n",
    "# print(\"All done!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ONLY PLOT SENSORS\n",
    "\n",
    "# def _plot_sigs(sig_chs, all_corrs=()):\n",
    "#     n_col = 1  # Only need one column for sensor locations\n",
    "#     n_row = len(conditions)\n",
    "#     figsize = (n_col * 2, n_row * 2)  # Increase figure size for better label visibility\n",
    "#     fig, axes = plt.subplots(\n",
    "#         n_row, n_col, figsize=figsize, constrained_layout=True)\n",
    "\n",
    "#     # Handle the case of a single subplot\n",
    "#     if n_row == 1:\n",
    "#         axes = [axes]\n",
    "\n",
    "#     for ci, condition in enumerate(conditions):\n",
    "#         sigs = sig_chs[condition]\n",
    "#         ax = axes[ci]  # Direct reference to each subplot's axis\n",
    "        \n",
    "#         # Ensure labels are set even if there are no significant sensors\n",
    "#         ax.set_ylabel(condition, labelpad=100)  # Increase labelpad if necessary\n",
    "\n",
    "#         # Only attempt to plot sensor locations if there are significant sensors\n",
    "#         if sigs[0][0] is not None:\n",
    "#             _plot_sig_chs(sigs, ax)\n",
    "#         else:\n",
    "#             # Optionally, clear the axes but keep them to display the label\n",
    "#             ax.clear()  # Clear the axes of any plotted data\n",
    "#             ax.set_xticks([])  # Remove x-ticks\n",
    "#             ax.set_yticks([])  # Remove y-ticks\n",
    "#             ax.spines['top'].set_visible(False)\n",
    "#             ax.spines['right'].set_visible(False)\n",
    "#             ax.spines['bottom'].set_visible(False)\n",
    "#             ax.spines['left'].set_visible(False)\n",
    "#     return fig\n",
    "\n",
    "# times = evokeds[conditions[0]][subjects[8]].times\n",
    "# info = evokeds[conditions[0]][subjects[8]].info\n",
    "# fig = _plot_sigs(sig_chs)\n",
    "\n",
    "# for ext in ('png', 'svg'):\n",
    "#     fig.savefig(op.join(results_path, f'sensors_{exp_name}.{ext}'))\n",
    "\n",
    "# print(\"All done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################\n",
    "# # Source space projection\n",
    "# import pyvista\n",
    "\n",
    "# info = use.copy().pick_types(fnirs='hbo', exclude=()).info\n",
    "# info['bads'] = []\n",
    "# assert tuple(zs) == conditions\n",
    "\n",
    "# evoked = mne.EvokedArray(np.array(list(zs.values())).T, info)\n",
    "# picks = np.arange(len(evoked.ch_names))\n",
    "\n",
    "# for ch in evoked.info['chs']:\n",
    "#     assert ch['coord_frame'] == mne.io.constants.FIFF.FIFFV_COORD_HEAD\n",
    "# stc = mne.stc_near_sensors(\n",
    "#     evoked, trans='fsaverage', subject='fsaverage', mode='weighted',\n",
    "#     distance=0.02, project=True, picks=picks, subjects_dir=subjects_dir)\n",
    "# # Split channel indices by left lat, posterior, right lat:\n",
    "# num_map = {name: str(ii) for ii, name in enumerate(evoked.ch_names)}\n",
    "# evoked.copy().rename_channels(num_map) #.plot_sensors(show_names=True)\n",
    "# view_map = [np.arange(19), np.arange(19, 33), np.arange(33, 52)]\n",
    "# surf = mne.read_bem_surfaces(  # brain surface\n",
    "#     f'{subjects_dir}/fsaverage/bem/fsaverage-5120-5120-5120-bem.fif', s_id=1)\n",
    "\n",
    "# for ci, condition in enumerate(conditions):\n",
    "#     this_sig = [v[0] // 2 for v in sig_chs[condition]]\n",
    "#     #assert np.in1d(this_sig, np.arange(52)).all()\n",
    "#     pos = np.array([info['chs'][idx]['loc'][:3] for idx in this_sig])\n",
    "#     pos.shape = (-1, 3)  # can be empty\n",
    "#     trans = mne.transforms._get_trans('fsaverage', 'head', 'mri')[0]\n",
    "#     pos = mne.transforms.apply_trans(trans, pos)  # now in MRI coords\n",
    "#     pos = mne.surface._project_onto_surface(pos, surf, project_rrs=True)[2]\n",
    "#     # plot\n",
    "#     brain = stc.plot(hemi='both', views=['lat', 'frontal', 'lat'],\n",
    "#                     initial_time=evoked.times[ci], cortex='low_contrast',\n",
    "#                     time_viewer=False, show_traces=False,\n",
    "#                     surface='pial', smoothing_steps=0, size=(1200, 400),\n",
    "#                     clim=dict(kind='value', pos_lims=[0., 1.25, 2.5]),\n",
    "#                     colormap='RdBu_r', view_layout='horizontal',\n",
    "#                     colorbar=(0, 1), time_label='', background='w',\n",
    "#                     brain_kwargs=dict(units='m'),\n",
    "#                     add_data_kwargs=dict(colorbar_kwargs=dict(\n",
    "#                         title_font_size=24, label_font_size=24, n_labels=5,\n",
    "#                         title='z score')), subjects_dir=subjects_dir)\n",
    "#     brain.show_view('lat', hemi='lh', row=0, col=0)\n",
    "#     brain.show_view(azimuth=270, elevation=90, row=0, col=1)\n",
    "#     pl = brain.plotter\n",
    "#     used = np.zeros(len(this_sig))\n",
    "#     brain.show_view('lat', hemi='rh', row=0, col=2)\n",
    "#     plt.imsave(\n",
    "#         op.join(results_path, f'all_brain_{exp_name}_{condition}.png'), pl.image)\n",
    "\n",
    "# print(\"All done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vtk==9.1.0 --> redid with conda --> 9.0.3 --> 9.0.3 ??\n",
    "# pyvistaqt==0.2.0 --> upgrade --> 0.11.1\n",
    "# pyvista==0.32.0 --> redid with pip --> 0.44.1\n",
    "# numpy 1.26.4 --> 1.19.5 --> 1.23.0\n",
    "# pip install vtk==9.1.0 --no-cache-dir\n",
    "# \"pip show X\" to see version // conda list vtk\n",
    "# conda install -c conda-forge vtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fOLD specificity\n",
    "import xlrd\n",
    "\n",
    "fold_files = ['10-10.xls', '10-5.xls']\n",
    "for fname in fold_files:\n",
    "    if not op.isfile(fname):\n",
    "        pooch.retrieve(f'https://github.com/nirx/fOLD-public/raw/master/Supplementary/{fname}', None, fname, path=os.getcwd())  # noqa\n",
    "raw_spec = use.copy()\n",
    "raw_spec.pick_channels(raw_spec.ch_names[::2])\n",
    "specs = mne_nirs.io.fold_channel_specificity(raw_spec, fold_files, 'Brodmann')\n",
    "for si, spec in enumerate(specs, 1):\n",
    "    spec['Channel'] = si\n",
    "    spec['negspec'] = -spec['Specificity']\n",
    "specs = pd.concat(specs, ignore_index=True)\n",
    "specs.drop(['Source', 'Detector', 'Distance (mm)', 'brainSens',\n",
    "            'X (mm)', 'Y (mm)', 'Z (mm)'], axis=1, inplace=True)\n",
    "specs.sort_values(['Channel', 'negspec'], inplace=True)\n",
    "specs.drop('negspec', axis=1, inplace=True)\n",
    "specs.reset_index(inplace=True, drop=True)\n",
    "specs.to_csv(op.join(results_path, 'specificity.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Condition Chroma      ch_name  subject  day    group         theta\n",
      "0             A    hbo  S10_D18 hbo      201    1  trained -1.577924e-05\n",
      "1             A    hbo  S10_D18 hbo      201    3  trained  3.961849e-06\n",
      "2            AV    hbo  S10_D18 hbo      201    1  trained  1.228112e-06\n",
      "3            AV    hbo  S10_D18 hbo      201    3  trained -5.628723e-06\n",
      "4             V    hbo  S10_D18 hbo      201    1  trained -7.734326e-06\n",
      "...         ...    ...          ...      ...  ...      ...           ...\n",
      "33595         V    hbr   S9_D21 hbr      234    3  control  5.178583e-06\n",
      "33596         W    hbr   S9_D21 hbr      234    1  control -1.054386e-06\n",
      "33597         W    hbr   S9_D21 hbr      234    3  control -5.320285e-06\n",
      "33598  constant    hbr   S9_D21 hbr      234    1  control -6.760430e-08\n",
      "33599  constant    hbr   S9_D21 hbr      234    3  control  6.881836e-07\n",
      "\n",
      "[33600 rows x 7 columns]\n",
      "      Condition  Chroma        ch_name  subject  day    group         theta\n",
      "0             A     hbo    S10_D18 hbo      201    1  trained -1.577924e-05\n",
      "1             A     hbo    S10_D18 hbo      201    3  trained  3.961849e-06\n",
      "2            AV     hbo    S10_D18 hbo      201    1  trained  1.228112e-06\n",
      "3            AV     hbo    S10_D18 hbo      201    3  trained -5.628723e-06\n",
      "4             V     hbo    S10_D18 hbo      201    1  trained -7.734326e-06\n",
      "...         ...     ...            ...      ...  ...      ...           ...\n",
      "50395         V  hbdiff  S9_D21 hbdiff      234    3  control -1.095537e-05\n",
      "50396         W  hbdiff  S9_D21 hbdiff      234    1  control  5.882260e-07\n",
      "50397         W  hbdiff  S9_D21 hbdiff      234    3  control  8.863095e-06\n",
      "50398  constant  hbdiff  S9_D21 hbdiff      234    1  control -4.176961e-07\n",
      "50399  constant  hbdiff  S9_D21 hbdiff      234    3  control -8.432042e-07\n",
      "\n",
      "[50400 rows x 7 columns]\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE HbDIFF\n",
    "\n",
    "# Load the data\n",
    "df_cha = pd.read_csv(op.join(results_path, 'df_cha_theta_tddr_bp_detrend.csv'))\n",
    "print(df_cha)\n",
    "df_cha_nolabels = df_cha.copy()\n",
    "df_cha_nolabels['ch_name'] = df_cha_nolabels['ch_name'].str[:-4]\n",
    "\n",
    "# Separate HbO and HbR\n",
    "df_hbo = df_cha_nolabels[df_cha_nolabels['Chroma'].str.endswith('hbo')].set_index(['subject', 'Condition', 'group', 'day', 'ch_name']).sort_index()\n",
    "df_hbr = df_cha_nolabels[df_cha_nolabels['Chroma'].str.endswith('hbr')].set_index(['subject', 'Condition', 'group', 'day', 'ch_name']).sort_index()\n",
    "\n",
    "# Compute the difference\n",
    "df_cha_diff_list = []\n",
    "for ch_name in df_hbo.index.get_level_values('ch_name').unique():\n",
    "    # Get aligned indices\n",
    "    df_hbo_ch = df_hbo.loc[(slice(None), slice(None), slice(None), slice(None), ch_name), :].sort_index()\n",
    "    df_hbr_ch = df_hbr.loc[(slice(None), slice(None), slice(None), slice(None), ch_name), :].sort_index()\n",
    "    \n",
    "    # Ensure df_hbo_ch and df_hbr_ch have the same length\n",
    "    common_index = df_hbo_ch.index.intersection(df_hbr_ch.index)\n",
    "    df_hbo_ch = df_hbo_ch.loc[common_index]\n",
    "    df_hbr_ch = df_hbr_ch.loc[common_index]\n",
    "    \n",
    "    # Calculate the difference\n",
    "    df_diff = df_hbo_ch[['theta']].sub(df_hbr_ch[['theta']])\n",
    "    \n",
    "    # Align df_cha_ch with df_diff\n",
    "    df_cha_ch = df_hbo_ch.reset_index()\n",
    "    df_cha_ch['theta'] = df_diff.values\n",
    "    df_cha_ch['Chroma'] = 'hbdiff'\n",
    "    df_cha_ch['ch_name'] = df_cha_ch['ch_name'] + ' hbdiff'\n",
    "    \n",
    "    if not df_cha_ch.empty:\n",
    "        df_cha_diff_list.append(df_cha_ch)\n",
    "\n",
    "df_cha_diff_concat = pd.concat(df_cha_diff_list, ignore_index=True)\n",
    "\n",
    "# Concatenate original df_cha with df_cha_diff_concat\n",
    "df_final = pd.concat([df_cha, df_cha_diff_concat], ignore_index=True)\n",
    "df_final.to_csv(op.join(results_path, 'df_combined_final_cha_tddr_bp.csv'), index=False)\n",
    "\n",
    "# Print the head of the resulting dataframe\n",
    "print(df_final)\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN T-TEST AND PLOT THE CHANGES OVER TIME\n",
    "\n",
    "# Source space projection - significant changes over time\n",
    "import pandas as pd\n",
    "import mne\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_rel, zscore\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from io import BytesIO\n",
    "\n",
    "raw_path = '../../data'\n",
    "proc_path = '../../processed'\n",
    "results_path = '../../results'\n",
    "subjects_dir = '../../subjects'\n",
    "\n",
    "groups = ['trained', 'control']\n",
    "chromas = ['hbo', 'hbr', 'hbdiff']\n",
    "conditions = ['A', 'V', 'AV']\n",
    "\n",
    "df_final = pd.read_csv(op.join(results_path, 'df_combined_final_cha_sdd.csv'))\n",
    "\n",
    "# Perform analysis for each group and Chroma\n",
    "for group in groups:\n",
    "    for chroma in chromas:\n",
    "        # Prepare figure for composite plots\n",
    "        fig, axes = plt.subplots(1, len(conditions), figsize=(15, 5))\n",
    "        for idx, condition in enumerate(conditions):\n",
    "            # Filter data for day 1 and day 3 for the specific group and Chroma\n",
    "            df_day1 = df_final.query(f\"group == '{group}' and Chroma == '{chroma}' and day == 1\").copy()\n",
    "            df_day3 = df_final.query(f\"group == '{group}' and Chroma == '{chroma}' and day == 3\").copy()\n",
    "\n",
    "            # Set index and sort\n",
    "            df_day1 = df_day1.set_index(['subject', 'ch_name', 'Condition', 'Chroma']).sort_index()\n",
    "            df_day3 = df_day3.set_index(['subject', 'ch_name', 'Condition', 'Chroma']).sort_index()\n",
    "            \n",
    "            # Merge dataframes to align day 1 and day 3 data\n",
    "            df_merged = df_day1[['theta']].rename(columns={'theta': 'theta_day1'}).merge(\n",
    "                df_day3[['theta']].rename(columns={'theta': 'theta_day3'}),\n",
    "                left_index=True, right_index=True)\n",
    "\n",
    "            # Calculate the difference and z-score\n",
    "            df_merged['theta_diff'] = df_merged['theta_day3'] - df_merged['theta_day1']\n",
    "            df_merged['z'] = zscore(df_merged['theta_diff'])\n",
    "\n",
    "            # Perform paired t-test for each channel and condition across subjects\n",
    "            t_stats = []\n",
    "            p_values = []\n",
    "            ch_names = []\n",
    "            condition_list = []\n",
    "\n",
    "            for (ch_name, cond), group_df in df_merged.groupby(['ch_name', 'Condition']):\n",
    "                t_stat, p_value = ttest_rel(group_df['theta_day1'], group_df['theta_day3'])\n",
    "                t_stats.append(t_stat)\n",
    "                p_values.append(p_value)\n",
    "                ch_names.append(ch_name)\n",
    "                condition_list.append(cond)\n",
    "\n",
    "            # Create a results DataFrame\n",
    "            results_df = pd.DataFrame({\n",
    "                'ch_name': ch_names,\n",
    "                'Condition': condition_list,\n",
    "                't_stat': t_stats,\n",
    "                'p_value': p_values\n",
    "            })\n",
    "\n",
    "            # Combine with z-score data\n",
    "            z_scores = df_merged.groupby(['ch_name', 'Condition'])['z'].mean().reset_index()\n",
    "            results_df = results_df.merge(z_scores, on=['ch_name', 'Condition'])\n",
    "\n",
    "            # Correct for multiple comparisons\n",
    "            print(f'Correcting for {len(results_df[\"p_value\"])} comparisons using FDR')\n",
    "            _, results_df['P_fdr'] = mne.stats.fdr_correction(results_df['p_value'], method='indep')\n",
    "            results_df['SIG'] = results_df['p_value'] < 0.05\n",
    "            \n",
    "            # Print significant results\n",
    "            significant_results = results_df.loc[results_df.SIG == True]\n",
    "            print(significant_results)\n",
    "\n",
    "            # Prepare data for brain plots\n",
    "            fname = op.join(proc_path, f'205_1_001_hbo_raw.fif')\n",
    "            use = mne.io.read_raw_fif(fname)\n",
    "            info = use.info\n",
    "\n",
    "            ch_of_interest = use.pick_channels([ch_name for ch_name in use.info['ch_names']])\n",
    "            info_of_interest = ch_of_interest.info\n",
    "\n",
    "            zs = {}\n",
    "            condition_data = results_df[(results_df['Condition'] == condition) & (results_df['SIG'] == True)]\n",
    "            \n",
    "            # Debugging prints\n",
    "            print(f\"\\nCondition: {condition}\")\n",
    "            print(f\"Group: {group}\")\n",
    "            print(f\"Chroma: {chroma}\")\n",
    "            print(f\"Condition Data:\\n{condition_data.head()}\")\n",
    "            \n",
    "            zs[condition] = np.array([\n",
    "                condition_data.loc[(condition_data['ch_name'] == ch_name) & (condition_data['SIG'] == True), 'z'].values[0]\n",
    "                if not condition_data.loc[(condition_data['ch_name'] == ch_name) & (condition_data['SIG'] == True), 'z'].empty\n",
    "                else 0\n",
    "                for ch_name in info_of_interest['ch_names']\n",
    "            ])\n",
    "            \n",
    "            # Create an EvokedArray for each condition\n",
    "            evoked = mne.EvokedArray(zs[condition][:, np.newaxis], info_of_interest)\n",
    "            picks = np.arange(len(info_of_interest['ch_names']))\n",
    "\n",
    "            stc = mne.stc_near_sensors(\n",
    "                evoked, trans='fsaverage', subject='fsaverage', mode='weighted',\n",
    "                distance=0.02, project=True, picks=picks, subjects_dir=subjects_dir)\n",
    "\n",
    "            # Plot the brain and capture the image in-memory\n",
    "            brain = stc.plot(hemi='both', views=['lat', 'frontal', 'lat'],\n",
    "                             cortex='low_contrast', time_viewer=False, show_traces=False,\n",
    "                             surface='pial', smoothing_steps=0, size=(1200, 400),\n",
    "                             clim=dict(kind='value', pos_lims=[0, 0.5, 1]),\n",
    "                             colormap='RdBu_r', view_layout='horizontal',\n",
    "                             colorbar=(0, 1), time_label='', background='w',\n",
    "                             brain_kwargs=dict(units='m'),\n",
    "                             add_data_kwargs=dict(colorbar_kwargs=dict(\n",
    "                                 title_font_size=24, label_font_size=20, n_labels=5,\n",
    "                                 title='z score')), subjects_dir=subjects_dir)\n",
    "            brain.show_view('lat', hemi='lh', row=0, col=0)\n",
    "            brain.show_view(azimuth=270, elevation=90, row=0, col=1)\n",
    "            brain.show_view('lat', hemi='rh', row=0, col=2)\n",
    "\n",
    "            # Capture the plot as an image in memory\n",
    "            screenshot = brain.screenshot(time_viewer=False)\n",
    "            brain.close()\n",
    "\n",
    "            # Display the image in the composite figure\n",
    "            ax = axes[idx]\n",
    "            ax.imshow(screenshot)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f'{group.capitalize()} - Condition {condition} ({chroma})', fontsize=18)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.savefig(op.join(results_path, f'{group}_{chroma}_composite_brain_plots_bp.png'))\n",
    "        plt.show()\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
