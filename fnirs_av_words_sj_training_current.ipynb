{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import compress\n",
    "from collections import defaultdict\n",
    "from mne.viz import plot_compare_evokeds\n",
    "import os\n",
    "from os import path as op\n",
    "import time\n",
    "import warnings\n",
    "from scipy import signal, stats\n",
    "import pooch\n",
    "import pandas as pd\n",
    "with warnings.catch_warnings(record=True):\n",
    "    warnings.simplefilter('ignore', FutureWarning)\n",
    "    from nilearn.glm.first_level import \\\n",
    "        make_first_level_design_matrix, compute_regressor  # noqa\n",
    "import statsmodels.formula.api as smf\n",
    "import mne_nirs.preprocessing\n",
    "import mne_nirs.statistics\n",
    "import mne_nirs.utils\n",
    "import mne_nirs.statistics\n",
    "import mne\n",
    "from mne.preprocessing.nirs import tddr\n",
    "import glob\n",
    "\n",
    "%matplotlib qt\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "subjects = ('201 202 203 204 205 206 207 208 209 212 213 214 215 216 217 218 219 221 223 224').split() #\n",
    "# Mapping of subjects to groups\n",
    "subject_to_group = {\n",
    "    201: \"trained\",\n",
    "    202: \"control\",\n",
    "    203: \"trained\",\n",
    "    204: \"control\",\n",
    "    205: \"control\",\n",
    "    206: \"control\",\n",
    "    207: \"trained\",\n",
    "    208: \"control\",\n",
    "    209: \"control\",\n",
    "    212: \"trained\",\n",
    "    213: \"trained\",\n",
    "    214: \"trained\",\n",
    "    215: \"control\",\n",
    "    216: \"trained\",\n",
    "    217: \"control\",\n",
    "    218: \"control\",\n",
    "    219: \"trained\",\n",
    "#    220: \"control\", #sampling rate = 2.40 Hz instead of 4.8\n",
    "    221: \"trained\",\n",
    "    223: \"trained\",\n",
    "    224: \"control\",\n",
    "}\n",
    "\n",
    "sfreq = 4.807692\n",
    "conditions = ('A', 'V', 'AV', 'W')\n",
    "groups = ('trained','control')\n",
    "days = ('1', '3')\n",
    "runs = (1, 2)\n",
    "\n",
    "condition_colors = dict(  # https://personal.sron.nl/~pault/data/colourschemes.pdf\n",
    "    A='#4477AA',  # sblue\n",
    "    AV='#CCBB44',  # yellow\n",
    "    V='#EE7733',  # orange\n",
    "    W='#AA3377',  # purple\n",
    ")\n",
    "exp_name = 'av'\n",
    "duration = 1.8\n",
    "design = 'event'\n",
    "plot_subject = '201'\n",
    "plot_run = 1\n",
    "beh_title, beh_idx = 'AV', 0\n",
    "filt_kwargs = dict(\n",
    "    l_freq=0.02, l_trans_bandwidth=0.02,\n",
    "    h_freq=0.2, h_trans_bandwidth=0.02)\n",
    "run_h = True  # regenerate HbO/HbR\n",
    "n_jobs = 4  # for GLM\n",
    "\n",
    "raw_path = '../../data'\n",
    "proc_path = '../../processed'\n",
    "results_path = '../../results'\n",
    "subjects_dir = '../../subjects'\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(proc_path, exist_ok=True)\n",
    "os.makedirs(subjects_dir, exist_ok=True)\n",
    "mne.datasets.fetch_fsaverage(subjects_dir=subjects_dir, verbose=True)\n",
    "use = None\n",
    "all_sci = list()\n",
    "plt.rcParams['axes.titlesize'] = 8\n",
    "plt.rcParams['axes.labelsize'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "got_bad = 0\n",
    "got_total = 0\n",
    "\n",
    "# Load participant data\n",
    "for subject in subjects[0 if run_h else subjects.index(plot_subject):]:\n",
    "    for day in days:\n",
    "        for run in runs:\n",
    "            group = subject_to_group.get(int(subject), \"unknown\")\n",
    "            root1 = f'Day{day}'\n",
    "            root2 = f'{subject}_{day}'\n",
    "            root3 = f'*-*-*_{run:03d}'\n",
    "            fname_base = op.join(raw_path, root1, root2, root3)\n",
    "            fname = glob.glob(fname_base)\n",
    "            print(fname)\n",
    "            base = f'{subject}_{day}_{run:03d}'\n",
    "            base_pr = base.ljust(20)\n",
    "            if not run_h:\n",
    "                if subject != plot_subject or run != plot_run:\n",
    "                    continue\n",
    "            raw_intensity = mne.io.read_raw_nirx(fname[0])\n",
    "#            raw_intensity.resample(sfreq=4.8)\n",
    "            raw_od = mne.preprocessing.nirs.optical_density(\n",
    "                raw_intensity, verbose='error')\n",
    "            # good/bad channels\n",
    "            peaks = np.ptp(raw_od.get_data('fnirs'), axis=-1)\n",
    "            flat_names = [\n",
    "                raw_od.ch_names[f].split(' ')[0]\n",
    "                for f in np.where(peaks < 0.001)[0]]\n",
    "            sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od)\n",
    "            all_sci.extend(sci)\n",
    "            sci_mask = (sci < 0.25)\n",
    "            got = np.where(sci_mask)[0]\n",
    "            got_bad = len(got) + got_bad\n",
    "            got_total = len(raw_od.ch_names) + got_total\n",
    "            print(f'    Run {base_pr}: {len(got)}/{len(raw_od.ch_names)} bad')\n",
    "            print(got_bad)\n",
    "            print(got_total)\n",
    "            # assign bads\n",
    "            assert raw_od.info['bads'] == []\n",
    "            bads = set(raw_od.ch_names[pick] for pick in got)\n",
    "            bads = bads | set(ch_name for ch_name in raw_od.ch_names\n",
    "                            if ch_name.split(' ')[0] in flat_names)\n",
    "            bads = sorted(bads)\n",
    "            raw_tddr = tddr(raw_od)\n",
    "            raw_tddr_bp = raw_tddr.copy().filter(**filt_kwargs)\n",
    "            raw_tddr_bp.info['bads'] = bads\n",
    "            picks = mne.pick_types(raw_tddr_bp.info, fnirs=True)\n",
    "            peaks = np.ptp(raw_tddr_bp.get_data(picks), axis=-1)\n",
    "            assert (peaks > 1e-5).all()\n",
    "            raw_tddr_bp.info['bads'] = []\n",
    "            raw_h = mne.preprocessing.nirs.beer_lambert_law(raw_tddr_bp, 6.)\n",
    "            # wait until now to assign bads so that we can choose later whether\n",
    "            # we want the MATLAB bads or the Python ones\n",
    "            h_bads = [\n",
    "                ch_name for ch_name in raw_h.ch_names\n",
    "                if ch_name.split(' ')[0] in set(bad.split(' ')[0] for bad in bads)]\n",
    "            assert len(bads) == len(h_bads)\n",
    "            raw_h.info['bads'] = h_bads\n",
    "            raw_h.info._check_consistency()\n",
    "            picks = mne.pick_types(raw_h.info, fnirs=True)\n",
    "            peaks = np.ptp(raw_h.get_data(picks), axis=-1)\n",
    "            assert (peaks > 1e-9).all()  # TODO: Maybe too small\n",
    "            raw_h.save(op.join(proc_path, f'{base}_hbo_raw.fif'), \n",
    "                       overwrite=True)   \n",
    "            if subject == plot_subject and run == plot_run:\n",
    "                use = None\n",
    "                assert use is None\n",
    "                use = dict(intensity=raw_intensity,\n",
    "                        od=raw_od,\n",
    "                        tddr=raw_tddr,\n",
    "                        h=raw_h,\n",
    "                        run=run,\n",
    "                        day=day,\n",
    "                        group=group)\n",
    "            del raw_intensity, raw_od, raw_tddr, raw_tddr_bp, raw_h\n",
    "\n",
    "assert isinstance(use, dict)\n",
    "ch_names = [ch_name.rstrip(' hbo') for ch_name in use['h'].ch_names[::2]]\n",
    "info = use['h'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Channel example figure\n",
    "\n",
    "for subject in subjects:\n",
    "    for day in days:\n",
    "        for run in runs:\n",
    "            fname = op.join(proc_path, f'{subject}_{day}_{run:03d}_hbo_raw.fif')\n",
    "            raw_h = mne.io.read_raw_fif(fname)\n",
    "            events, _ = mne.events_from_annotations(raw_h)\n",
    "            print(len(events))\n",
    "\n",
    "def _make_design(raw_h, design, subject=None, run=None, day=None, group=None):\n",
    "    annotations_to_remove = raw_h.annotations.description == '255.0'\n",
    "    raw_h.annotations.delete(annotations_to_remove)\n",
    "    events, _ = mne.events_from_annotations(raw_h)\n",
    "    rows_to_remove = events[:, -1] == 1\n",
    "    events = events[~rows_to_remove]\n",
    "    # mis-codings\n",
    "    if len(events)==101:\n",
    "        events = events[1:]\n",
    "    n_times = len(raw_h.times)\n",
    "    stim = np.zeros((n_times, 4))\n",
    "    events[:, 2] -= 1\n",
    "    assert len(events) == 100, len(events)\n",
    "    want = [0] + [25] * 4\n",
    "    count = np.bincount(events[:, 2])\n",
    "    assert np.array_equal(count, want), count\n",
    "    assert events.shape == (100, 3), events.shape\n",
    "    mne.viz.plot_events(events)\n",
    "    if design == 'block':\n",
    "        events = events[0::5]\n",
    "        duration = 20.\n",
    "        assert np.array_equal(np.bincount(events[:, 2]), [0] + [5] * 4)\n",
    "    else:\n",
    "        assert design == 'event'\n",
    "        assert len(events) == 100\n",
    "        duration = 1.8\n",
    "        assert events.shape == (100, 3)\n",
    "        events_r = events[:, 2].reshape(20, 5)\n",
    "        assert (events_r == events_r[:, :1]).all()\n",
    "        del events_r\n",
    "    idx = (events[:, [0, 2]] - [0, 1]).T\n",
    "    assert np.in1d(idx[1], np.arange(len(conditions))).all()\n",
    "    stim[tuple(idx)] = 1\n",
    "    assert raw_h.info['sfreq'] == sfreq  # necessary for below logic to work\n",
    "    n_block = int(np.ceil(duration * sfreq))\n",
    "    stim = signal.fftconvolve(stim, np.ones((n_block, 1)), axes=0)[:n_times]\n",
    "    dm_events = pd.DataFrame({\n",
    "        'trial_type': [conditions[ii] for ii in idx[1]],\n",
    "        'onset': idx[0] / raw_h.info['sfreq'],\n",
    "        'duration': n_block / raw_h.info['sfreq']})\n",
    "    dm = make_first_level_design_matrix(\n",
    "        raw_h.times, dm_events, hrf_model='glover',\n",
    "        drift_model='polynomial', drift_order=0)\n",
    "    return stim, dm, events\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Plot the design matrix and some raw traces\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6., 3), constrained_layout=True)\n",
    "# Design\n",
    "ax = axes[0]\n",
    "raw_h = use['h']\n",
    "stim, dm, _ = _make_design(raw_h, design)\n",
    "for ci, condition in enumerate(conditions):\n",
    "    color = condition_colors[condition]\n",
    "    ax.fill_between(\n",
    "        raw_h.times, stim[:, ci], 0, edgecolor='none', facecolor='k',\n",
    "        alpha=0.5)\n",
    "    model = dm[conditions[ci]].to_numpy()\n",
    "    ax.plot(raw_h.times, model, ls='-', lw=1, color=color)\n",
    "    x = raw_h.times[np.where(model > 0)[0][0]]\n",
    "    ax.text(\n",
    "        x + 10, 1.1, condition, color=color, fontweight='bold', ha='center')\n",
    "ax.set(ylabel='Modeled\\noxyHb', xlabel='', xlim=raw_h.times[[0, -1]])\n",
    "\n",
    "# HbO/HbR\n",
    "ax = axes[1]\n",
    "picks = [pi for pi, ch_name in enumerate(raw_h.ch_names)\n",
    "         if 'S1_D2' in ch_name]\n",
    "assert len(picks) == 2\n",
    "fnirs_colors = dict(hbo='r', hbr='b')\n",
    "ylim = np.array([-0.5, 0.5])\n",
    "for pi, pick in enumerate(picks):\n",
    "    color = fnirs_colors[raw_h.ch_names[pick][-3:]]\n",
    "    data = raw_h.get_data(pick)[0] * 1e6\n",
    "    val = np.ptp(data)\n",
    "    assert val > 0.01\n",
    "    ax.plot(raw_h.times, data, color=color, lw=1.)\n",
    "ax.set(ylim=ylim, xlabel='Time (s)', ylabel='μM',\n",
    "       xlim=raw_h.times[[0, -1]])\n",
    "del raw_h\n",
    "for ax in axes:\n",
    "    for key in ('top', 'right'):\n",
    "        ax.spines[key].set_visible(False)\n",
    "for ext in ('png', 'svg'):\n",
    "    fig.savefig(\n",
    "        op.join(\n",
    "            results_path, f'figure_1_{exp_name}.{ext}'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Run GLM analysis and epoching\n",
    "\n",
    "sfreq = 4.807692050933838\n",
    "\n",
    "df_cha = pd.DataFrame()\n",
    "for day in days:\n",
    "    for subject in subjects:\n",
    "        fname = op.join(proc_path, f'{subject}_{day}_{exp_name}.h5')\n",
    "        if not op.isfile(fname):\n",
    "            group = subject_to_group.get(int(subject), \"unknown\")\n",
    "            fname = op.join(proc_path, f'{subject}_{day}_{exp_name}.h5')\n",
    "            subj_cha = pd.DataFrame()\n",
    "            t0 = time.time()\n",
    "            for run in runs:\n",
    "                print(f'Running GLM for {group} {subject} day {day} run {run:03d}... ', end='')\n",
    "                fname2 = op.join(proc_path, f'{subject}_{day}_{run:03d}_hbo_raw.fif')\n",
    "                raw_h = mne.io.read_raw_fif(fname2)\n",
    "                _, dm, _ = _make_design(raw_h, design, subject, run, day, group)\n",
    "                glm_est = mne_nirs.statistics.run_glm(\n",
    "                    raw_h, dm, noise_model='ols', n_jobs=n_jobs)\n",
    "                cha = glm_est.to_dataframe()\n",
    "                cha['subject'] = subject\n",
    "                cha['run'] = run\n",
    "                cha['day'] = day\n",
    "                cha['group'] = group\n",
    "                cha['good'] = ~np.in1d(cha['ch_name'], bads)\n",
    "                subj_cha = pd.concat([subj_cha, cha], ignore_index=True)\n",
    "                del raw_h\n",
    "            subj_cha.to_hdf(fname, 'subj_cha', mode='w')\n",
    "            print(f'{time.time() - t0:0.1f} sec')\n",
    "        df_cha = pd.concat([df_cha, pd.read_hdf(fname)], ignore_index=True)\n",
    "df_cha.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# block averages\n",
    "event_id = {condition: ci for ci, condition in enumerate(conditions, 1)}\n",
    "evokeds = {condition: dict() for condition in conditions}\n",
    "for day in days:\n",
    "    for subject in subjects:\n",
    "        fname = op.join(\n",
    "            proc_path, f'{subject}_{day}_{exp_name}-ave.fif')\n",
    "        if not op.isfile(fname):\n",
    "            tmin, tmax = -2, 38\n",
    "            baseline = (None, 0)\n",
    "            t0 = time.time()\n",
    "            print(f'Creating block average for {subject} ... ', end='')\n",
    "            raws = list()\n",
    "            events = list()\n",
    "            for run in runs:\n",
    "                fname2 = op.join(proc_path, f'{subject}_{day}_{run:03d}_hbo_raw.fif')\n",
    "                raw_h = mne.io.read_raw_fif(fname2)\n",
    "                events.append(_make_design(raw_h, 'block', subject, run)[2])\n",
    "                raws.append(raw_h)\n",
    "            bads = sorted(set(sum((r.info['bads'] for r in raws), [])))\n",
    "            for r in raws:\n",
    "                r.info['bads'] = bads\n",
    "            raw_h, events = mne.concatenate_raws(raws, events_list=events)\n",
    "            epochs = mne.Epochs(raw_h, events, event_id, tmin=tmin, tmax=tmax,\n",
    "                                baseline=baseline)\n",
    "            this_ev = [epochs[condition].average() for condition in conditions]\n",
    "            assert all(ev.nave > 0 for ev in this_ev)\n",
    "            mne.write_evokeds(fname, this_ev, overwrite=True)\n",
    "            print(f'{time.time() - t0:0.1f} sec')\n",
    "        for condition in conditions:\n",
    "            evokeds[condition][subject] = mne.read_evokeds(fname, condition)\n",
    "\n",
    "# Exclude bad channels\n",
    "bad = dict()\n",
    "for day in days:\n",
    "    for subject in subjects:\n",
    "        for run in runs:\n",
    "            fname2 = op.join(proc_path, f'{subject}_{day}_{run:03d}_hbo_raw.fif')\n",
    "            this_info = mne.io.read_info(fname2)\n",
    "            bad_channels = [idx - 1 for idx in sorted(\n",
    "                this_info['ch_names'].index(bad) + 1 for bad in this_info['bads'])]\n",
    "            valid_indices = np.arange(len(use['h'].ch_names))\n",
    "            bb = [b for b in bad_channels if b in valid_indices]\n",
    "            bad[(subject, run, day)] = bb\n",
    "#        assert np.in1d(bad[(subject, run, day)], np.arange(len(use['h'].ch_names))).all()  # noqa: E501\n",
    "\n",
    "# make life easier by combining across runs\n",
    "bad_combo = dict()\n",
    "for day in days:\n",
    "    for (subject, run, day), bb in bad.items():\n",
    "        bad_combo[subject] = sorted(set(bad_combo.get(subject, [])) | set(bb))\n",
    "bad = bad_combo\n",
    "assert set(bad) == set(subjects)\n",
    "start = len(df_cha)\n",
    "n_drop = 0\n",
    "for day in days:\n",
    "    for (subject, run, day), bb in bad.items():\n",
    "        if not len(bb):\n",
    "            continue\n",
    "        drop_names = [use['h'].ch_names[b] for b in bb]\n",
    "        is_subject = (df_cha['subject'] == subject)\n",
    "        is_day = (df_cha['day'] == day)\n",
    "        assert len(is_subject) == len(df_cha)\n",
    "        is_day = (df_cha['day'] == day)\n",
    "        drop = df_cha.index[\n",
    "            is_subject &\n",
    "            is_day &\n",
    "            np.in1d(df_cha['ch_name'], drop_names)]\n",
    "        n_drop += len(drop)\n",
    "        if len(drop):\n",
    "            print(f'Dropping {len(drop)} for {subject} day {day}')  # {run}')\n",
    "            df_cha.drop(drop, inplace=True)\n",
    "end = len(df_cha)\n",
    "assert n_drop == start - end, (n_drop, start - end)\n",
    "\n",
    "# combine runs by averaging estimates\n",
    "sorts = ['subject', 'ch_name', 'Chroma', 'Condition', 'group', 'day', 'run']\n",
    "df_cha.sort_values(\n",
    "    sorts, inplace=True)\n",
    "assert (np.array(df_cha['run']).reshape(-1, 2) == runs).all()\n",
    "theta = np.array(df_cha['theta']).reshape(-1, len(runs)).mean(-1)\n",
    "df_cha.drop(\n",
    "    [col for col in df_cha.columns if col not in sorts[:-1]], axis='columns',\n",
    "    inplace=True)\n",
    "df_cha.reset_index(drop=True, inplace=True)\n",
    "df_cha = df_cha[::len(runs)]\n",
    "df_cha.reset_index(drop=True, inplace=True)\n",
    "df_cha['theta'] = theta\n",
    "df_cha.to_csv(op.join(results_path, 'df_cha.csv'), index=False)\n",
    "df_cha.to_csv(op.join('df_cha.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed linear model\n",
    "df_cha_diff = pd.read_csv(op.join(results_path, 'df_cha_diff.csv'))\n",
    "print(df_cha_diff)\n",
    "\n",
    "def _mixed_df(ch_summary):\n",
    "    formula = \"theta_diff ~ -1 + ch_name:Condition\" \n",
    "    ch_model = smf.mixedlm(  \n",
    "        formula, ch_summary, groups=ch_summary[\"subject\"]).fit(method='powell')\n",
    "    ch_model_df = mne_nirs.statistics.statsmodels_to_results(ch_model)\n",
    "    ch_model_df['P>|z|'] = ch_model.pvalues\n",
    "    ch_model_df.drop([idx for idx in ch_model_df.index if '[constant]' in idx],\n",
    "                    inplace=True)\n",
    "    return ch_model_df\n",
    "\n",
    "# Run group level model and convert to dataframe\n",
    "use_subjects = [subj for subj in subjects]\n",
    "ch_summary = df_cha_diff.query(\"Chroma in ['hbo'] & group in ['trained']\").copy()\n",
    "ch_summary_use = ch_summary.query(\n",
    "    f\"subject in {use_subjects}\").copy()\n",
    "ch_model_df = _mixed_df(ch_summary_use) \n",
    "ch_model_df.reset_index(inplace=True)\n",
    "\n",
    "# Correct for multiple comparisons\n",
    "print(f'Correcting for {len(ch_model_df[\"P>|z|\"])} comparisons using FDR')\n",
    "_, ch_model_df['P_fdr'] = mne.stats.fdr_correction(\n",
    "    ch_model_df['P>|z|'], method='indep')\n",
    "ch_model_df['SIG'] = ch_model_df['P_fdr'] < 0.05\n",
    "ch_model_df.to_csv(op.join('ch_model_corrected.csv'), index=False)\n",
    "ch_model_df.loc[ch_model_df.SIG == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Plot significant channels\n",
    "\n",
    "sig_chs = dict()\n",
    "zs = dict()\n",
    "for condition in conditions:\n",
    "    sig_df = ch_model_df[\n",
    "        (ch_model_df['P_fdr'] < 0.05) &\n",
    "        (ch_model_df['Condition'] == condition)]\n",
    "    sig_chs[(condition)] = sorted(\n",
    "        (use['h'].ch_names.index(row[1]['ch_name']), row[1]['P_fdr'])\n",
    "        for row in sig_df.iterrows())\n",
    "    ch_model_df[ch_model_df['Condition'] == condition]\n",
    "    zs[condition] = np.array([\n",
    "        ch_model_df.loc[(ch_model_df['Condition'] == condition) & \n",
    "\n",
    "                        (ch_model_df['ch_name'] == ch_name), 'z'].iloc[0]\n",
    "        for ch_name in info['ch_names'][::2]], float)\n",
    "    assert zs[condition].shape == (84,)\n",
    "    assert np.isfinite(zs[condition]).all()\n",
    "\n",
    "\n",
    "def _plot_sig_chs(sigs, ax):\n",
    "    if sigs and isinstance(sigs[0], tuple):\n",
    "        sigs = [s[0] for s in sigs]\n",
    "    ch_groups = [sigs, np.setdiff1d(np.arange(info['nchan']), sigs)]\n",
    "    mne.viz.plot_sensors(\n",
    "        info, 'topomap', 'hbo', title='', axes=ax,\n",
    "        show_names=True, ch_groups=ch_groups)\n",
    "    ax.collections[0].set(lw=0)\n",
    "    c = ax.collections[0].get_facecolor()\n",
    "    c[(c[:, :3] == (0.5, 0, 0)).all(-1)] = (0., 0., 0., 0.1)\n",
    "    c[(c[:, :3] == (0, 0, 0.5)).all(-1)] = (0., 1., 0., 0.5)\n",
    "    ax.collections[0].set_facecolor(c)\n",
    "    ch_names = [info['ch_names'][idx] for idx in sigs]\n",
    "    texts = list(ax.texts)\n",
    "    got = []\n",
    "    for text in list(texts):\n",
    "        try:\n",
    "            idx = ch_names.index(text.get_text())\n",
    "        except ValueError:\n",
    "            text.remove()\n",
    "        else:\n",
    "            got.append(idx)\n",
    "            text.set_text(f'{sigs[idx] // 2 + 1}')\n",
    "            text.set(fontsize='xx-small', zorder=5, ha='center')\n",
    "    assert len(got) == len(sigs), (got, list(sigs))\n",
    "\n",
    "def _plot_sigs(sig_chs, all_corrs=()):\n",
    "    n_col = max(len(x) for x in sig_chs.values()) + 1\n",
    "    n_row = len(conditions)\n",
    "    figsize = (n_col * 1.0, n_row * 1.0)\n",
    "    fig, axes = plt.subplots(\n",
    "        n_row, n_col, figsize=figsize, constrained_layout=True, squeeze=False)\n",
    "    h_colors = {0: 'r', 1: 'b'}\n",
    "    xticks = [0, 10, 20, 30]\n",
    "    ylim = [-0.2, 0.3]\n",
    "    yticks = [-0.2, -0.1, 0, 0.1, 0.2, 0.3]\n",
    "    xlim = [times[0], 35]\n",
    "    ylim = np.array(ylim)\n",
    "    yticks = np.array(yticks)\n",
    "    for ci, condition in enumerate(conditions):\n",
    "        ii = 0\n",
    "        sigs = sig_chs[condition]\n",
    "        if len(sigs) == 0:\n",
    "            sigs = [(None, None)]\n",
    "        for ii, (ch_idx, ch_p) in enumerate(sigs):\n",
    "            ax = axes[ci, ii]\n",
    "            if ch_idx is not None:\n",
    "                for jj in range(2):  # HbO, HbR\n",
    "                    color = h_colors[jj]\n",
    "                    a = 1e6 * np.array(\n",
    "                        [evokeds[condition][subject].data[ch_idx + jj]\n",
    "                         for subject in use_subjects\n",
    "                         if ch_idx + jj not in bad.get(subject, [])], float)\n",
    "                    m = np.mean(a, axis=0)\n",
    "                    lower, upper = stats.t.interval(\n",
    "                        0.95, len(a) - 1, loc=m, scale=stats.sem(a, axis=0))\n",
    "                    ax.fill_between(\n",
    "                        times, lower, upper, facecolor=color,\n",
    "                        edgecolor='none', lw=0, alpha=0.25, zorder=3,\n",
    "                        clip_on=False)\n",
    "                    ax.plot(times, m, color=color, lw=1, zorder=4,\n",
    "                            clip_on=False)\n",
    "                # Correlations\n",
    "                this_df = ch_summary_use.query(\n",
    "                    f'ch_name == {repr(use[\"h\"].ch_names[ch_idx])} and '\n",
    "                    f'Chroma == \"hbo\" and '\n",
    "                    f'Condition == {repr(condition)}')\n",
    "                #assert 8 <= len(this_df) <= len(subjects), len(this_df)\n",
    "                a = np.array(this_df['theta'])\n",
    "                cs = list()\n",
    "                if len(cs):\n",
    "                    cs = [''] + cs\n",
    "                c = '\\n'.join(cs)\n",
    "                ax.text(times[-1], ylim[1],\n",
    "                        f'ch{ch_idx // 2 + 1}\\np={ch_p:0.5f}{c}',\n",
    "                        ha='right', va='top', fontsize='x-small')\n",
    "            ax.axvline(20, ls=':', color='0.5', zorder=2, lw=1)\n",
    "            ax.axhline(0, ls='-', color='k', zorder=2, lw=0.5)\n",
    "            ax.set(xticks=xticks, yticks=yticks)\n",
    "            ax.set(xlim=xlim, ylim=ylim)\n",
    "            for key in ('top', 'right'):\n",
    "                ax.spines[key].set_visible(False)\n",
    "            if ax.get_subplotspec().is_last_row():\n",
    "                ax.set(xlabel='Time (sec)')\n",
    "            else:\n",
    "                ax.set_xticklabels([''] * len(xticks))\n",
    "            if ax.get_subplotspec().is_first_col():\n",
    "                ax.set_ylabel(condition)\n",
    "            else:\n",
    "                ax.set_yticklabels([''] * len(yticks))\n",
    "            for key in ('top', 'right'):\n",
    "                ax.spines[key].set_visible(False)\n",
    "        for ii in range(ii + 1, n_col - 1):\n",
    "            fig.delaxes(axes[ci, ii])\n",
    "        # montage\n",
    "        ax = axes[ci, -1]\n",
    "        if sigs[0][0] is None:\n",
    "            fig.delaxes(ax)\n",
    "        else:\n",
    "            # plot montage\n",
    "            _plot_sig_chs(sigs, ax)\n",
    "    return fig\n",
    "\n",
    "times = evokeds[conditions[0]][subjects[0]].times\n",
    "info = evokeds[conditions[0]][subjects[0]].info\n",
    "fig = _plot_sigs(sig_chs)\n",
    "for ext in ('png', 'svg'):\n",
    "    fig.savefig(op.join(results_path, f'stats_{exp_name}.{ext}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Source space projection\n",
    "\n",
    "import pyvista\n",
    "import pyvistaqt\n",
    "\n",
    "info = use['h'].copy().pick_types(fnirs='hbo', exclude=()).info\n",
    "info['bads'] = []\n",
    "assert tuple(zs) == conditions\n",
    "\n",
    "evoked = mne.EvokedArray(np.array(list(zs.values())).T, info)\n",
    "picks = np.arange(len(evoked.ch_names))\n",
    "\n",
    "for ch in evoked.info['chs']:\n",
    "    assert ch['coord_frame'] == mne.io.constants.FIFF.FIFFV_COORD_HEAD\n",
    "stc = mne.stc_near_sensors(\n",
    "    evoked, trans='fsaverage', subject='fsaverage', mode='weighted',\n",
    "    distance=0.02, project=True, picks=picks, subjects_dir=subjects_dir)\n",
    "# Split channel indices by left lat, posterior, right lat:\n",
    "num_map = {name: str(ii) for ii, name in enumerate(evoked.ch_names)}\n",
    "evoked.copy().rename_channels(num_map).plot_sensors(show_names=True)\n",
    "view_map = [np.arange(19), np.arange(19, 33), np.arange(33, 52)]\n",
    "surf = mne.read_bem_surfaces(  # brain surface\n",
    "    f'{subjects_dir}/fsaverage/bem/fsaverage-5120-5120-5120-bem.fif', s_id=1)\n",
    "\n",
    "for ci, condition in enumerate(conditions):\n",
    "    this_sig = [v[0] // 2 for v in sig_chs[condition]]\n",
    "    #assert np.in1d(this_sig, np.arange(52)).all()\n",
    "    pos = np.array([info['chs'][idx]['loc'][:3] for idx in this_sig])\n",
    "    pos.shape = (-1, 3)  # can be empty\n",
    "    trans = mne.transforms._get_trans('fsaverage', 'head', 'mri')[0]\n",
    "    pos = mne.transforms.apply_trans(trans, pos)  # now in MRI coords\n",
    "    pos = mne.surface._project_onto_surface(pos, surf, project_rrs=True)[2]\n",
    "    # plot\n",
    "    brain = stc.plot(hemi='both', views=['lat', 'frontal', 'lat'],\n",
    "                    initial_time=evoked.times[ci], cortex='low_contrast',\n",
    "                    time_viewer=False, show_traces=False,\n",
    "                    surface='pial', smoothing_steps=0, size=(1200, 400),\n",
    "                    clim=dict(kind='value', pos_lims=[0., 1.25, 2.5]),\n",
    "                    colormap='RdBu_r', view_layout='horizontal',\n",
    "                    colorbar=(0, 1), time_label='', background='w',\n",
    "                    brain_kwargs=dict(units='m'),\n",
    "                    add_data_kwargs=dict(colorbar_kwargs=dict(\n",
    "                        title_font_size=24, label_font_size=24, n_labels=5,\n",
    "                        title='z score')), subjects_dir=subjects_dir)\n",
    "    brain.show_view('lat', hemi='lh', row=0, col=0)\n",
    "    brain.show_view(azimuth=270, elevation=90, row=0, col=1)\n",
    "    pl = brain.plotter\n",
    "    used = np.zeros(len(this_sig))\n",
    "    brain.show_view('lat', hemi='rh', row=0, col=2)\n",
    "    plt.imsave(\n",
    "        op.join(results_path, f'trained_brain_{exp_name}_{condition}.png'), pl.image)\n",
    "\n",
    "# fOLD specificity\n",
    "fold_files = ['10-10.xls', '10-5.xls']\n",
    "for fname in fold_files:\n",
    "    if not op.isfile(fname):\n",
    "        pooch.retrieve(f'https://github.com/nirx/fOLD-public/raw/master/Supplementary/{fname}', None, fname, path=os.getcwd())  # noqa\n",
    "raw_spec = use['h'].copy()\n",
    "raw_spec.pick_channels(raw_spec.ch_names[::2])\n",
    "specs = mne_nirs.io.fold_channel_specificity(raw_spec, fold_files, 'Brodmann')\n",
    "for si, spec in enumerate(specs, 1):\n",
    "    spec['Channel'] = si\n",
    "    spec['negspec'] = -spec['Specificity']\n",
    "specs = pd.concat(specs, ignore_index=True)\n",
    "specs.drop(['Source', 'Detector', 'Distance (mm)', 'brainSens',\n",
    "            'X (mm)', 'Y (mm)', 'Z (mm)'], axis=1, inplace=True)\n",
    "specs.sort_values(['Channel', 'negspec'], inplace=True)\n",
    "specs.drop('negspec', axis=1, inplace=True)\n",
    "specs.reset_index(inplace=True, drop=True)\n",
    "specs.to_csv(op.join(results_path, 'specificity.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
